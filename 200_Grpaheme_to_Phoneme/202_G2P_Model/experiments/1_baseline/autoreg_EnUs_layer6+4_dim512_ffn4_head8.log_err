AutoregressiveTransformer(
  (encoder_embedding): Embedding(31, 512)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (decoder_embedding): Embedding(72, 512)
  (pos_decoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer): Transformer(
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (decoder): TransformerDecoder(
      (layers): ModuleList(
        (0): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
        (1): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
        (2): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
        (3): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (linear1): Linear(in_features=512, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=512, bias=True)
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (fc_out): Linear(in_features=512, out_features=72, bias=True)
)
CrossEntropyLoss(
  (criterion): CrossEntropyLoss()
)
Training on device: cuda
Epoch: 1 | Step 183 | Train Loss: 4.008
Epoch: 2 | Step 366 | Train Loss: 3.244
Epoch: 3 | Step 549 | Train Loss: 2.794
Epoch: 4 | Step 732 | Train Loss: 2.466
Epoch: 5 | Step 915 | Train Loss: 2.211
Epoch: 6 | Step 1098 | Train Loss: 1.933
Epoch: 7 | Step 1281 | Train Loss: 1.758
Epoch: 8 | Step 1464 | Train Loss: 1.538
Epoch: 9 | Step 1647 | Train Loss: 1.251
Epoch: 10 | Step 1830 | Train Loss: 1.013
Epoch: 11 | Step 2000 | Valid Loss: 0.8594
Epoch: 11 | Step 2000 | Mean PER: 0.3084906552791254 | Mean WER: 0.7313191489361702
Achieving better result (mean_per): 0.3085
Epoch: 11 | Step 2013 | Train Loss: 0.8546
Epoch: 12 | Step 2196 | Train Loss: 0.7427
Epoch: 13 | Step 2379 | Train Loss: 0.6776
Epoch: 14 | Step 2562 | Train Loss: 0.5656
Epoch: 15 | Step 2745 | Train Loss: 0.5246
Epoch: 16 | Step 2928 | Train Loss: 0.4759
Epoch: 17 | Step 3111 | Train Loss: 0.4407
Epoch: 18 | Step 3294 | Train Loss: 0.4197
Epoch: 19 | Step 3477 | Train Loss: 0.3905
Epoch: 20 | Step 3660 | Train Loss: 0.3617
Epoch: 21 | Step 3843 | Train Loss: 0.3529
Epoch: 22 | Step 4000 | Valid Loss: 0.3320
Epoch: 22 | Step 4000 | Mean PER: 0.14965067095501292 | Mean WER: 0.4786382978723404
Achieving better result (mean_per): 0.1497
Epoch: 22 | Step 4026 | Train Loss: 0.3336
Epoch: 23 | Step 4209 | Train Loss: 0.3169
Epoch: 24 | Step 4392 | Train Loss: 0.3057
Epoch: 25 | Step 4575 | Train Loss: 0.2980
Epoch: 26 | Step 4758 | Train Loss: 0.2875
Epoch: 27 | Step 4941 | Train Loss: 0.2773
Epoch: 28 | Step 5124 | Train Loss: 0.2742
Epoch: 29 | Step 5307 | Train Loss: 0.2646
Epoch: 30 | Step 5490 | Train Loss: 0.2635
Epoch: 31 | Step 5673 | Train Loss: 0.2467
Epoch: 32 | Step 5856 | Train Loss: 0.2484
Epoch: 33 | Step 6000 | Valid Loss: 0.2391
Epoch: 33 | Step 6000 | Mean PER: 0.11381234881552453 | Mean WER: 0.388
Achieving better result (mean_per): 0.1138
Epoch: 33 | Step 6039 | Train Loss: 0.2350
Epoch: 34 | Step 6222 | Train Loss: 0.2349
Epoch: 35 | Step 6405 | Train Loss: 0.2276
Epoch: 36 | Step 6588 | Train Loss: 0.2230
Epoch: 37 | Step 6771 | Train Loss: 0.2200
Epoch: 38 | Step 6954 | Train Loss: 0.2183
Epoch: 39 | Step 7137 | Train Loss: 0.2100
Epoch: 40 | Step 7320 | Train Loss: 0.2076
Epoch: 41 | Step 7503 | Train Loss: 0.2008
Epoch: 42 | Step 7686 | Train Loss: 0.1931
Epoch: 43 | Step 7869 | Train Loss: 0.1888
Epoch: 44 | Step 8000 | Valid Loss: 0.1883
Epoch: 44 | Step 8000 | Mean PER: 0.10619062419762429 | Mean WER: 0.3678297872340425
Achieving better result (mean_per): 0.1062
Epoch: 44 | Step 8052 | Train Loss: 0.1904
Epoch: 45 | Step 8235 | Train Loss: 0.1849
Epoch: 46 | Step 8418 | Train Loss: 0.1809
Epoch: 47 | Step 8601 | Train Loss: 0.1850
Epoch: 48 | Step 8784 | Train Loss: 0.1758
Epoch: 49 | Step 8967 | Train Loss: 0.1661
Epoch: 50 | Step 9150 | Train Loss: 0.1624
Epoch: 51 | Step 9333 | Train Loss: 0.1631
Epoch: 52 | Step 9516 | Train Loss: 0.1562
Epoch: 53 | Step 9699 | Train Loss: 0.1510
Epoch: 54 | Step 9882 | Train Loss: 0.1597
Epoch: 55 | Step 10000 | Valid Loss: 0.1663
Epoch: 55 | Step 10000 | Mean PER: 0.0975148312815038 | Mean WER: 0.3474893617021277
Achieving better result (mean_per): 0.09751
Epoch: 55 | Step 10065 | Train Loss: 0.1600
Epoch: 56 | Step 10248 | Train Loss: 0.1412
Epoch: 57 | Step 10431 | Train Loss: 0.1377
Epoch: 58 | Step 10614 | Train Loss: 0.1345
Epoch: 59 | Step 10797 | Train Loss: 0.1276
Epoch: 60 | Step 10980 | Train Loss: 0.1264
Epoch: 61 | Step 11163 | Train Loss: 0.1220
Epoch: 62 | Step 11346 | Train Loss: 0.1264
Epoch: 63 | Step 11529 | Train Loss: 0.1140
Epoch: 64 | Step 11712 | Train Loss: 0.1118
Epoch: 65 | Step 11895 | Train Loss: 0.1079
Epoch: 66 | Step 12000 | Valid Loss: 0.1083
Epoch: 66 | Step 12000 | Mean PER: 0.09135258584575467 | Mean WER: 0.3252765957446809
Achieving better result (mean_per): 0.09135
Epoch: 66 | Step 12078 | Train Loss: 0.1046
Epoch: 67 | Step 12261 | Train Loss: 0.1031
Epoch: 68 | Step 12444 | Train Loss: 0.09976
Epoch: 69 | Step 12627 | Train Loss: 0.09841
Epoch: 70 | Step 12810 | Train Loss: 0.09288
Epoch: 71 | Step 12993 | Train Loss: 0.09210
Epoch: 72 | Step 13176 | Train Loss: 0.08610
Epoch: 73 | Step 13359 | Train Loss: 0.08911
Epoch: 74 | Step 13542 | Train Loss: 0.08289
Epoch: 75 | Step 13725 | Train Loss: 0.07876
Epoch: 76 | Step 13908 | Train Loss: 0.08020
Epoch: 77 | Step 14000 | Valid Loss: 0.07323
Epoch: 77 | Step 14000 | Mean PER: 0.08417681320017838 | Mean WER: 0.30748936170212765
Achieving better result (mean_per): 0.08418
Epoch: 77 | Step 14091 | Train Loss: 0.07627
Epoch: 78 | Step 14274 | Train Loss: 0.07564
Epoch: 79 | Step 14457 | Train Loss: 0.07247
Epoch: 80 | Step 14640 | Train Loss: 0.06982
Epoch: 81 | Step 14823 | Train Loss: 0.06797
Epoch: 82 | Step 15006 | Train Loss: 0.06630
Epoch: 83 | Step 15189 | Train Loss: 0.06541
Epoch: 84 | Step 15372 | Train Loss: 0.06164
Epoch: 85 | Step 15555 | Train Loss: 0.05998
Epoch: 86 | Step 15738 | Train Loss: 0.05995
Epoch: 87 | Step 15921 | Train Loss: 0.06025
Epoch: 88 | Step 16000 | Valid Loss: 0.05679
Epoch: 88 | Step 16000 | Mean PER: 0.08198759442695172 | Mean WER: 0.300936170212766
Achieving better result (mean_per): 0.08199
Epoch: 88 | Step 16104 | Train Loss: 0.05851
Epoch: 89 | Step 16287 | Train Loss: 0.05390
Epoch: 90 | Step 16470 | Train Loss: 0.05348
Epoch: 91 | Step 16653 | Train Loss: 0.05357
Epoch: 92 | Step 16836 | Train Loss: 0.05378
Epoch: 93 | Step 17019 | Train Loss: 0.05481
Epoch: 94 | Step 17202 | Train Loss: 0.05044
Epoch: 95 | Step 17385 | Train Loss: 0.04748
Epoch: 96 | Step 17568 | Train Loss: 0.04653
Epoch: 97 | Step 17751 | Train Loss: 0.04748
Epoch: 98 | Step 17934 | Train Loss: 0.04378
Epoch: 99 | Step 18000 | Valid Loss: 0.04233
Epoch: 99 | Step 18000 | Mean PER: 0.08102812200164868 | Mean WER: 0.29693617021276597
Achieving better result (mean_per): 0.08103
Epoch: 99 | Step 18117 | Train Loss: 0.04353
Epoch: 100 | Step 18300 | Train Loss: 0.04506
Epoch: 101 | Step 18483 | Train Loss: 0.04103
Epoch: 102 | Step 18666 | Train Loss: 0.04400
Epoch: 103 | Step 18849 | Train Loss: 0.04088
Epoch: 104 | Step 19032 | Train Loss: 0.03965
Epoch: 105 | Step 19215 | Train Loss: 0.03915
Epoch: 106 | Step 19398 | Train Loss: 0.04558
Epoch: 107 | Step 19581 | Train Loss: 0.03908
Epoch: 108 | Step 19764 | Train Loss: 0.03582
Epoch: 109 | Step 19947 | Train Loss: 0.03515
Epoch: 110 | Step 20000 | Valid Loss: 0.02853
Epoch: 110 | Step 20000 | Mean PER: 0.07960918390789065 | Mean WER: 0.2948936170212766
Achieving better result (mean_per): 0.07961
Epoch: 110 | Step 20130 | Train Loss: 0.03575
Epoch: 111 | Step 20313 | Train Loss: 0.03518
Epoch: 112 | Step 20496 | Train Loss: 0.03320
Epoch: 113 | Step 20679 | Train Loss: 0.03370
Epoch: 114 | Step 20862 | Train Loss: 0.03286
Epoch: 115 | Step 21045 | Train Loss: 0.03221
Epoch: 116 | Step 21228 | Train Loss: 0.03334
Epoch: 117 | Step 21411 | Train Loss: 0.03230
Epoch: 118 | Step 21594 | Train Loss: 0.03117
Epoch: 119 | Step 21777 | Train Loss: 0.03276
Epoch: 120 | Step 21960 | Train Loss: 0.03103
Epoch: 121 | Step 22000 | Valid Loss: 0.02640
Epoch: 121 | Step 22000 | Mean PER: 0.08059568372545575 | Mean WER: 0.29395744680851066
Epoch: 121 | Step 22143 | Train Loss: 0.03114
Epoch: 122 | Step 22326 | Train Loss: 0.03016
Epoch: 123 | Step 22509 | Train Loss: 0.03093
Epoch: 124 | Step 22692 | Train Loss: 0.03031
Epoch: 125 | Step 22875 | Train Loss: 0.02955
Epoch: 126 | Step 23058 | Train Loss: 0.02918
Epoch: 127 | Step 23241 | Train Loss: 0.02808
Epoch: 128 | Step 23424 | Train Loss: 0.02725
Epoch: 129 | Step 23607 | Train Loss: 0.02785
Epoch: 130 | Step 23790 | Train Loss: 0.02577
Epoch: 131 | Step 23973 | Train Loss: 0.02693
Epoch: 132 | Step 24000 | Valid Loss: 0.02638
Epoch: 132 | Step 24000 | Mean PER: 0.0791226908471736 | Mean WER: 0.29097872340425535
Achieving better result (mean_per): 0.07912
Epoch: 132 | Step 24156 | Train Loss: 0.02763
Epoch: 133 | Step 24339 | Train Loss: 0.02633
Epoch: 134 | Step 24522 | Train Loss: 0.02536
Epoch: 135 | Step 24705 | Train Loss: 0.02500
Epoch: 136 | Step 24888 | Train Loss: 0.02437
Epoch: 137 | Step 25071 | Train Loss: 0.02538
Epoch: 138 | Step 25254 | Train Loss: 0.02451
Epoch: 139 | Step 25437 | Train Loss: 0.02393
Epoch: 140 | Step 25620 | Train Loss: 0.02344
Epoch: 141 | Step 25803 | Train Loss: 0.02507
Epoch: 142 | Step 25986 | Train Loss: 0.02332
Epoch: 143 | Step 26000 | Valid Loss: 0.02061
Epoch: 143 | Step 26000 | Mean PER: 0.07809564994121543 | Mean WER: 0.2907234042553192
Achieving better result (mean_per): 0.07810
Epoch: 143 | Step 26169 | Train Loss: 0.02194
Epoch: 144 | Step 26352 | Train Loss: 0.02389
Epoch: 145 | Step 26535 | Train Loss: 0.02414
Epoch: 146 | Step 26718 | Train Loss: 0.02228
Epoch: 147 | Step 26901 | Train Loss: 0.02163
Epoch: 148 | Step 27084 | Train Loss: 0.02103
Epoch: 149 | Step 27267 | Train Loss: 0.02207
Epoch: 150 | Step 27450 | Train Loss: 0.02192
Epoch: 151 | Step 27633 | Train Loss: 0.02120
Epoch: 152 | Step 27816 | Train Loss: 0.02083
Epoch: 153 | Step 27999 | Train Loss: 0.01988
Epoch: 154 | Step 28000 | Valid Loss: inf
Epoch: 154 | Step 28000 | Mean PER: 0.07781186232246382 | Mean WER: 0.2913191489361702
Achieving better result (mean_per): 0.07781
Epoch: 154 | Step 28182 | Train Loss: 0.02163
Epoch: 155 | Step 28365 | Train Loss: 0.02185
Epoch: 156 | Step 28548 | Train Loss: 0.02218
Epoch: 157 | Step 28731 | Train Loss: 0.01986
Epoch: 158 | Step 28914 | Train Loss: 0.01911
Epoch: 159 | Step 29097 | Train Loss: 0.01925
Epoch: 160 | Step 29280 | Train Loss: 0.01843
Epoch: 161 | Step 29463 | Train Loss: 0.01772
Epoch: 162 | Step 29646 | Train Loss: 0.01974
Epoch: 163 | Step 29829 | Train Loss: 0.02067
Epoch: 164 | Step 30000 | Valid Loss: 0.02325
Epoch: 164 | Step 30000 | Mean PER: 0.07873079365937377 | Mean WER: 0.2917446808510638
Epoch: 164 | Step 30012 | Train Loss: 0.02321
Epoch: 165 | Step 30195 | Train Loss: 0.01887
Epoch: 166 | Step 30378 | Train Loss: 0.01886
Epoch: 167 | Step 30561 | Train Loss: 0.01865
Epoch: 168 | Step 30744 | Train Loss: 0.01758
Epoch: 169 | Step 30927 | Train Loss: 0.01847
Epoch: 170 | Step 31110 | Train Loss: 0.01820
Epoch: 171 | Step 31293 | Train Loss: 0.01852
Epoch: 172 | Step 31476 | Train Loss: 0.01805
Epoch: 173 | Step 31659 | Train Loss: 0.01720
Epoch: 174 | Step 31842 | Train Loss: 0.01633
Epoch: 175 | Step 32000 | Valid Loss: 0.01608
Epoch: 175 | Step 32000 | Mean PER: 0.0788794443168151 | Mean WER: 0.29123404255319146
Epoch: 175 | Step 32025 | Train Loss: 0.01642
Epoch: 176 | Step 32208 | Train Loss: 0.01804
Epoch: 177 | Step 32391 | Train Loss: 0.01794
Epoch: 178 | Step 32574 | Train Loss: 0.01725
Epoch: 179 | Step 32757 | Train Loss: 0.01590
Epoch: 180 | Step 32940 | Train Loss: 0.01618
Epoch: 181 | Step 33123 | Train Loss: 0.01617
Epoch: 182 | Step 33306 | Train Loss: 0.01811
Epoch: 183 | Step 33489 | Train Loss: 0.01592
Epoch: 184 | Step 33672 | Train Loss: 0.01651
Epoch: 185 | Step 33855 | Train Loss: 0.01552
Epoch: 186 | Step 34000 | Valid Loss: 0.01828
Epoch: 186 | Step 34000 | Mean PER: 0.07877133474776686 | Mean WER: 0.29114893617021276
Epoch: 186 | Step 34038 | Train Loss: 0.01846
Epoch: 187 | Step 34221 | Train Loss: 0.01607
Epoch: 188 | Step 34404 | Train Loss: 0.01402
Epoch: 189 | Step 34587 | Train Loss: 0.01483
Epoch: 190 | Step 34770 | Train Loss: 0.01534
Epoch: 191 | Step 34953 | Train Loss: 0.01521
Epoch: 192 | Step 35136 | Train Loss: 0.01474
Epoch: 193 | Step 35319 | Train Loss: 0.01476
Epoch: 194 | Step 35502 | Train Loss: 0.01597
Epoch: 195 | Step 35685 | Train Loss: 0.01569
Epoch: 196 | Step 35868 | Train Loss: 0.01486
Epoch: 197 | Step 36000 | Valid Loss: 0.01536
Epoch: 197 | Step 36000 | Mean PER: 0.07917674563169773 | Mean WER: 0.29617021276595745
Epoch: 197 | Step 36051 | Train Loss: 0.01488
Epoch: 198 | Step 36234 | Train Loss: 0.01470
Epoch: 199 | Step 36417 | Train Loss: 0.01473
Epoch: 200 | Step 36600 | Train Loss: 0.01418
Epoch: 201 | Step 36783 | Train Loss: 0.01473
Epoch: 202 | Step 36966 | Train Loss: 0.01513
Epoch: 203 | Step 37149 | Train Loss: 0.01535
Epoch: 204 | Step 37332 | Train Loss: 0.01480
Epoch: 205 | Step 37515 | Train Loss: 0.01494
Epoch: 206 | Step 37698 | Train Loss: 0.01441
Epoch: 207 | Step 37881 | Train Loss: 0.01416
Epoch: 208 | Step 38000 | Valid Loss: 0.01356
Epoch: 208 | Step 38000 | Mean PER: 0.07720374599656753 | Mean WER: 0.28748936170212763
Achieving better result (mean_per): 0.07720
Epoch: 208 | Step 38064 | Train Loss: 0.01352
Epoch: 209 | Step 38247 | Train Loss: 0.01419
Epoch: 210 | Step 38430 | Train Loss: 0.01289
Epoch: 211 | Step 38613 | Train Loss: 0.01309
Epoch: 212 | Step 38796 | Train Loss: 0.01326
Epoch: 213 | Step 38979 | Train Loss: 0.01382
Epoch: 214 | Step 39162 | Train Loss: 0.01314
Epoch: 215 | Step 39345 | Train Loss: 0.01284
Epoch: 216 | Step 39528 | Train Loss: 0.01374
Epoch: 217 | Step 39711 | Train Loss: 0.01330
Epoch: 218 | Step 39894 | Train Loss: 0.01378
Epoch: 219 | Step 40000 | Valid Loss: 0.01195
Epoch: 219 | Step 40000 | Mean PER: 0.07746050622305707 | Mean WER: 0.28808510638297874
Epoch: 219 | Step 40077 | Train Loss: 0.01287
Epoch: 220 | Step 40260 | Train Loss: 0.01446
Epoch: 221 | Step 40443 | Train Loss: 0.01296
Epoch: 222 | Step 40626 | Train Loss: 0.01262
Epoch: 223 | Step 40809 | Train Loss: 0.01217
Epoch: 224 | Step 40992 | Train Loss: 0.01238
Epoch: 225 | Step 41175 | Train Loss: 0.01296
Epoch: 226 | Step 41358 | Train Loss: 0.01323
Epoch: 227 | Step 41541 | Train Loss: 0.01272
Epoch: 228 | Step 41724 | Train Loss: 0.01228
Epoch: 229 | Step 41907 | Train Loss: 0.01285
Epoch: 230 | Step 42000 | Valid Loss: 0.01181
Epoch: 230 | Step 42000 | Mean PER: 0.07917674563169773 | Mean WER: 0.29097872340425535
Epoch: 230 | Step 42090 | Train Loss: 0.01201
Epoch: 231 | Step 42273 | Train Loss: 0.01162
Epoch: 232 | Step 42456 | Train Loss: 0.01340
Epoch: 233 | Step 42639 | Train Loss: 0.01308
Epoch: 234 | Step 42822 | Train Loss: 0.01289
Epoch: 235 | Step 43005 | Train Loss: 0.01229
Epoch: 236 | Step 43188 | Train Loss: 0.01147
Epoch: 237 | Step 43371 | Train Loss: 0.01108
Epoch: 238 | Step 43554 | Train Loss: 0.01172
Epoch: 239 | Step 43737 | Train Loss: 0.01161
Epoch: 240 | Step 43920 | Train Loss: 0.01197
Epoch: 241 | Step 44000 | Valid Loss: 0.01174
Epoch: 241 | Step 44000 | Mean PER: 0.07913620454330464 | Mean WER: 0.2924255319148936
Epoch: 241 | Step 44103 | Train Loss: 0.01187
Epoch: 242 | Step 44286 | Train Loss: 0.01254
Epoch: 243 | Step 44469 | Train Loss: 0.01219
Epoch: 244 | Step 44652 | Train Loss: 0.01219
Epoch: 245 | Step 44835 | Train Loss: 0.01179
Epoch: 246 | Step 45018 | Train Loss: 0.01168
Epoch: 247 | Step 45201 | Train Loss: 0.01109
Epoch: 248 | Step 45384 | Train Loss: 0.01119
Epoch: 249 | Step 45567 | Train Loss: 0.01073
Epoch: 250 | Step 45750 | Train Loss: 0.01137
Epoch: 251 | Step 45933 | Train Loss: 0.01415
Epoch: 252 | Step 46000 | Valid Loss: 0.01276
Epoch: 252 | Step 46000 | Mean PER: 0.07791997189151205 | Mean WER: 0.28629787234042553
Epoch: 252 | Step 46116 | Train Loss: 0.01200
Epoch: 253 | Step 46299 | Train Loss: 0.01079
Epoch: 254 | Step 46482 | Train Loss: 0.01108
Epoch: 255 | Step 46665 | Train Loss: 0.01127
Epoch: 256 | Step 46848 | Train Loss: 0.01127
Epoch: 257 | Step 47031 | Train Loss: 0.01026
Epoch: 258 | Step 47214 | Train Loss: 0.01133
Epoch: 259 | Step 47397 | Train Loss: 0.01040
Epoch: 260 | Step 47580 | Train Loss: 0.01183
Epoch: 261 | Step 47763 | Train Loss: 0.01035
Epoch: 262 | Step 47946 | Train Loss: 0.009739
Epoch: 263 | Step 48000 | Valid Loss: 0.009987
Epoch: 263 | Step 48000 | Mean PER: 0.07698752685847106 | Mean WER: 0.28272340425531917
Achieving better result (mean_per): 0.07699
Epoch: 263 | Step 48129 | Train Loss: 0.01014
Epoch: 264 | Step 48312 | Train Loss: 0.01141
Epoch: 265 | Step 48495 | Train Loss: 0.01145
Epoch: 266 | Step 48678 | Train Loss: 0.01109
Epoch: 267 | Step 48861 | Train Loss: 0.009951
Epoch: 268 | Step 49044 | Train Loss: 0.009638
Epoch: 269 | Step 49227 | Train Loss: 0.009849
Epoch: 270 | Step 49410 | Train Loss: 0.009841
Epoch: 271 | Step 49593 | Train Loss: 0.01072
Epoch: 272 | Step 49776 | Train Loss: 0.01091
Epoch: 273 | Step 49959 | Train Loss: 0.01095
Epoch: 274 | Step 50000 | Valid Loss: 0.01054
Epoch: 274 | Step 50000 | Mean PER: 0.07758212948823633 | Mean WER: 0.2857021276595745
Epoch: 274 | Step 50142 | Train Loss: 0.009811
Epoch: 275 | Step 50325 | Train Loss: 0.01043
Epoch: 276 | Step 50508 | Train Loss: 0.008946
Epoch: 277 | Step 50691 | Train Loss: 0.009362
Epoch: 278 | Step 50874 | Train Loss: 0.009844
Epoch: 279 | Step 51057 | Train Loss: 0.01028
Epoch: 280 | Step 51240 | Train Loss: 0.01079
Epoch: 281 | Step 51423 | Train Loss: 0.01019
Epoch: 282 | Step 51606 | Train Loss: 0.01069
Epoch: 283 | Step 51789 | Train Loss: 0.01014
Epoch: 284 | Step 51972 | Train Loss: 0.009208
Epoch: 285 | Step 52000 | Valid Loss: 0.008204
Epoch: 285 | Step 52000 | Mean PER: 0.0780821362450844 | Mean WER: 0.28902127659574467
Epoch: 285 | Step 52155 | Train Loss: 0.009564
Epoch: 286 | Step 52338 | Train Loss: 0.009499
Epoch: 287 | Step 52521 | Train Loss: 0.009572
Epoch: 288 | Step 52704 | Train Loss: 0.008768
Epoch: 289 | Step 52887 | Train Loss: 0.009442
Epoch: 290 | Step 53070 | Train Loss: 0.01056
Epoch: 291 | Step 53253 | Train Loss: 0.01019
Epoch: 292 | Step 53436 | Train Loss: 0.009787
Epoch: 293 | Step 53619 | Train Loss: 0.008967
Epoch: 294 | Step 53802 | Train Loss: 0.009319
Epoch: 295 | Step 53985 | Train Loss: 0.01025
Epoch: 296 | Step 54000 | Valid Loss: 0.006534
Epoch: 296 | Step 54000 | Mean PER: 0.07727131447722267 | Mean WER: 0.28672340425531917
Epoch: 296 | Step 54168 | Train Loss: 0.008905
Epoch: 297 | Step 54351 | Train Loss: 0.009542
Epoch: 298 | Step 54534 | Train Loss: 0.009138
Epoch: 299 | Step 54717 | Train Loss: 0.009670
Epoch: 300 | Step 54900 | Train Loss: 0.01030
Epoch: 301 | Step 55083 | Train Loss: 0.009652
Epoch: 302 | Step 55266 | Train Loss: 0.009699
Epoch: 303 | Step 55449 | Train Loss: 0.009380
Epoch: 304 | Step 55632 | Train Loss: 0.009351
Epoch: 305 | Step 55815 | Train Loss: 0.009277
Epoch: 306 | Step 55998 | Train Loss: 0.009264
Epoch: 307 | Step 56000 | Valid Loss: 0.008605
Epoch: 307 | Step 56000 | Mean PER: 0.07750104731145016 | Mean WER: 0.2857021276595745
Epoch: 307 | Step 56181 | Train Loss: 0.01007
Epoch: 308 | Step 56364 | Train Loss: 0.009866
Epoch: 309 | Step 56547 | Train Loss: 0.01007
Epoch: 310 | Step 56730 | Train Loss: 0.008513
Epoch: 311 | Step 56913 | Train Loss: 0.01033
Epoch: 312 | Step 57096 | Train Loss: 0.009090
Epoch: 313 | Step 57279 | Train Loss: 0.008919
Epoch: 314 | Step 57462 | Train Loss: 0.008266
Epoch: 315 | Step 57645 | Train Loss: 0.009017
Epoch: 316 | Step 57828 | Train Loss: 0.008309
Epoch: 317 | Step 58000 | Valid Loss: 0.008570
Epoch: 317 | Step 58000 | Mean PER: 0.07727131447722267 | Mean WER: 0.28638297872340424
Epoch: 317 | Step 58011 | Train Loss: 0.008588
Epoch: 318 | Step 58194 | Train Loss: 0.008508
Epoch: 319 | Step 58377 | Train Loss: 0.008192
Epoch: 320 | Step 58560 | Train Loss: 0.008350
Epoch: 321 | Step 58743 | Train Loss: 0.008790
Epoch: 322 | Step 58926 | Train Loss: 0.009130
Epoch: 323 | Step 59109 | Train Loss: 0.008437
Epoch: 324 | Step 59292 | Train Loss: 0.008177
Epoch: 325 | Step 59475 | Train Loss: 0.009510
Epoch: 326 | Step 59658 | Train Loss: 0.009090
Epoch: 327 | Step 59841 | Train Loss: 0.008535
Epoch: 328 | Step 60000 | Valid Loss: 0.008830
Epoch: 328 | Step 60000 | Mean PER: 0.0770010405546021 | Mean WER: 0.2835744680851064
Epoch: 328 | Step 60024 | Train Loss: 0.008951
Epoch: 329 | Step 60207 | Train Loss: 0.005548
Epoch: 330 | Step 60390 | Train Loss: 0.003930
Epoch: 331 | Step 60573 | Train Loss: 0.003519
Epoch: 332 | Step 60756 | Train Loss: 0.003384
Epoch: 333 | Step 60939 | Train Loss: 0.003243
Epoch: 334 | Step 61122 | Train Loss: 0.003152
Epoch: 335 | Step 61305 | Train Loss: 0.003265
Epoch: 336 | Step 61488 | Train Loss: 0.003056
Epoch: 337 | Step 61671 | Train Loss: 0.003009
Epoch: 338 | Step 61854 | Train Loss: 0.002885
Epoch: 339 | Step 62000 | Valid Loss: 0.002942
Epoch: 339 | Step 62000 | Mean PER: 0.07440641089744456 | Mean WER: 0.2762553191489362
Achieving better result (mean_per): 0.07441
Epoch: 339 | Step 62037 | Train Loss: 0.002922
Epoch: 340 | Step 62220 | Train Loss: 0.002831
Epoch: 341 | Step 62403 | Train Loss: 0.002907
Epoch: 342 | Step 62586 | Train Loss: 0.003078
Epoch: 343 | Step 62769 | Train Loss: 0.002883
Epoch: 344 | Step 62952 | Train Loss: 0.003377
Epoch: 345 | Step 63135 | Train Loss: 0.003314
Epoch: 346 | Step 63318 | Train Loss: 0.003056
Epoch: 347 | Step 63501 | Train Loss: 0.003353
Epoch: 348 | Step 63684 | Train Loss: 0.003111
Epoch: 349 | Step 63867 | Train Loss: 0.003191
Epoch: 350 | Step 64000 | Valid Loss: 0.003015
Epoch: 350 | Step 64000 | Mean PER: 0.07521723266530629 | Mean WER: 0.27906382978723404
Epoch: 350 | Step 64050 | Train Loss: 0.003002
Epoch: 351 | Step 64233 | Train Loss: 0.002945
Epoch: 352 | Step 64416 | Train Loss: 0.003089
Epoch: 353 | Step 64599 | Train Loss: 0.002997
Epoch: 354 | Step 64782 | Train Loss: 0.003256
Epoch: 355 | Step 64965 | Train Loss: 0.002722
Epoch: 356 | Step 65148 | Train Loss: 0.002959
Epoch: 357 | Step 65331 | Train Loss: 0.003115
Epoch: 358 | Step 65514 | Train Loss: 0.002961
Epoch: 359 | Step 65697 | Train Loss: 0.003108
Epoch: 360 | Step 65880 | Train Loss: 0.003075
Epoch: 361 | Step 66000 | Valid Loss: 0.003140
Epoch: 361 | Step 66000 | Mean PER: 0.07582534899120258 | Mean WER: 0.2822978723404255
Epoch: 361 | Step 66063 | Train Loss: 0.002901
Epoch: 362 | Step 66246 | Train Loss: 0.002862
Epoch: 363 | Step 66429 | Train Loss: 0.003165
Epoch: 364 | Step 66612 | Train Loss: 0.003290
Epoch: 365 | Step 66795 | Train Loss: 0.002969
Epoch: 366 | Step 66978 | Train Loss: 0.002940
Epoch: 367 | Step 67161 | Train Loss: 0.003159
Epoch: 368 | Step 67344 | Train Loss: 0.002987
Epoch: 369 | Step 67527 | Train Loss: 0.003074
Epoch: 370 | Step 67710 | Train Loss: 0.003018
Epoch: 371 | Step 67893 | Train Loss: 0.003169
Epoch: 372 | Step 68000 | Valid Loss: 0.002963
Epoch: 372 | Step 68000 | Mean PER: 0.0768659035932918 | Mean WER: 0.28391489361702127
Epoch: 372 | Step 68076 | Train Loss: 0.002962
Epoch: 373 | Step 68259 | Train Loss: 0.002749
Epoch: 374 | Step 68442 | Train Loss: 0.002835
Epoch: 375 | Step 68625 | Train Loss: 0.002932
Epoch: 376 | Step 68808 | Train Loss: 0.002981
Epoch: 377 | Step 68991 | Train Loss: 0.002973
Epoch: 378 | Step 69174 | Train Loss: 0.002963
Epoch: 379 | Step 69357 | Train Loss: 0.002589
Epoch: 380 | Step 69540 | Train Loss: 0.002762
Epoch: 381 | Step 69723 | Train Loss: 0.002740
Epoch: 382 | Step 69906 | Train Loss: 0.002691
Epoch: 383 | Step 70000 | Valid Loss: 0.002822
Epoch: 383 | Step 70000 | Mean PER: 0.07571723942215436 | Mean WER: 0.27906382978723404
Epoch: 383 | Step 70089 | Train Loss: 0.002917
Epoch: 384 | Step 70272 | Train Loss: 0.003144
Epoch: 385 | Step 70455 | Train Loss: 0.002902
Epoch: 386 | Step 70638 | Train Loss: 0.002595
Epoch: 387 | Step 70821 | Train Loss: 0.002627
Epoch: 388 | Step 71004 | Train Loss: 0.002545
Epoch: 389 | Step 71187 | Train Loss: 0.002716
Epoch: 390 | Step 71370 | Train Loss: 0.003074
Epoch: 391 | Step 71553 | Train Loss: 0.002624
Epoch: 392 | Step 71736 | Train Loss: 0.002869
Epoch: 393 | Step 71919 | Train Loss: 0.002642
Epoch: 394 | Step 72000 | Valid Loss: 0.002581
Epoch: 394 | Step 72000 | Mean PER: 0.07564967094149921 | Mean WER: 0.281531914893617
Epoch: 394 | Step 72102 | Train Loss: 0.002850
Epoch: 395 | Step 72285 | Train Loss: 0.003087
Epoch: 396 | Step 72468 | Train Loss: 0.003111
Epoch: 397 | Step 72651 | Train Loss: 0.002850
Epoch: 398 | Step 72834 | Train Loss: 0.002760
Epoch: 399 | Step 73017 | Train Loss: 0.002612
Epoch: 400 | Step 73200 | Train Loss: 0.002733
Epoch: 401 | Step 73383 | Train Loss: 0.002801
Epoch: 402 | Step 73566 | Train Loss: 0.002600
Epoch: 403 | Step 73749 | Train Loss: 0.002598
Epoch: 404 | Step 73932 | Train Loss: 0.002587
Epoch: 405 | Step 74000 | Valid Loss: 0.002793
Epoch: 405 | Step 74000 | Mean PER: 0.07583886268733361 | Mean WER: 0.2805957446808511
Epoch: 405 | Step 74115 | Train Loss: 0.002389
Epoch: 406 | Step 74298 | Train Loss: 0.001843
Epoch: 407 | Step 74481 | Train Loss: 0.001526
Epoch: 408 | Step 74664 | Train Loss: 0.001525
Epoch: 409 | Step 74847 | Train Loss: 0.001478
Epoch: 410 | Step 75030 | Train Loss: 0.001434
Epoch: 411 | Step 75213 | Train Loss: 0.001350
Epoch: 412 | Step 75396 | Train Loss: 0.001344
Epoch: 413 | Step 75579 | Train Loss: 0.001133
Epoch: 414 | Step 75762 | Train Loss: 0.001418
Epoch: 415 | Step 75945 | Train Loss: 0.001208
Epoch: 416 | Step 76000 | Valid Loss: 0.001335
Epoch: 416 | Step 76000 | Mean PER: 0.07502804091947189 | Mean WER: 0.27804255319148935
Epoch: 416 | Step 76128 | Train Loss: 0.001223
Epoch: 417 | Step 76311 | Train Loss: 0.001219
Epoch: 418 | Step 76494 | Train Loss: 0.001219
Epoch: 419 | Step 76677 | Train Loss: 0.001186
Epoch: 420 | Step 76860 | Train Loss: 0.001344
Epoch: 421 | Step 77043 | Train Loss: 0.001252
Epoch: 422 | Step 77226 | Train Loss: 0.001208
Epoch: 423 | Step 77409 | Train Loss: 0.001234
Epoch: 424 | Step 77592 | Train Loss: 0.001262
Epoch: 425 | Step 77775 | Train Loss: 0.001253
Epoch: 426 | Step 77958 | Train Loss: 0.001124
Epoch: 427 | Step 78000 | Valid Loss: 0.001147
Epoch: 427 | Step 78000 | Mean PER: 0.07443343828970662 | Mean WER: 0.2781276595744681
Epoch: 427 | Step 78141 | Train Loss: 0.001073
Epoch: 428 | Step 78324 | Train Loss: 0.001166
Epoch: 429 | Step 78507 | Train Loss: 0.001241
Epoch: 430 | Step 78690 | Train Loss: 0.001181
Epoch: 431 | Step 78873 | Train Loss: 0.001192
Epoch: 432 | Step 79056 | Train Loss: 0.001116
Epoch: 433 | Step 79239 | Train Loss: 0.001048
Epoch: 434 | Step 79422 | Train Loss: 0.001198
Epoch: 435 | Step 79605 | Train Loss: 0.001060
Epoch: 436 | Step 79788 | Train Loss: 0.001007
Epoch: 437 | Step 79971 | Train Loss: 0.001315
Epoch: 438 | Step 80000 | Valid Loss: 0.001109
Epoch: 438 | Step 80000 | Mean PER: 0.07609562291382316 | Mean WER: 0.28195744680851065
Epoch: 438 | Step 80154 | Train Loss: 0.001149
Epoch: 439 | Step 80337 | Train Loss: 0.001099
Epoch: 440 | Step 80520 | Train Loss: 0.001027
Epoch: 441 | Step 80703 | Train Loss: 0.001043
Epoch: 442 | Step 80886 | Train Loss: 0.001227
Epoch: 443 | Step 81069 | Train Loss: 0.001080
Epoch: 444 | Step 81252 | Train Loss: 0.001071
Epoch: 445 | Step 81435 | Train Loss: 0.001182
Epoch: 446 | Step 81618 | Train Loss: 0.001068
Epoch: 447 | Step 81801 | Train Loss: 0.001072
Epoch: 448 | Step 81984 | Train Loss: 0.001087
Epoch: 449 | Step 82000 | Valid Loss: 0.001543
Epoch: 449 | Step 82000 | Mean PER: 0.07563615724536818 | Mean WER: 0.2794042553191489
Epoch: 449 | Step 82167 | Train Loss: 0.001151
Epoch: 450 | Step 82350 | Train Loss: 0.001124
Epoch: 451 | Step 82533 | Train Loss: 0.001059
Epoch: 452 | Step 82716 | Train Loss: 0.001086
Epoch: 453 | Step 82899 | Train Loss: 0.001073
Epoch: 454 | Step 83082 | Train Loss: 0.001071
Epoch: 455 | Step 83265 | Train Loss: 0.001134
Epoch: 456 | Step 83448 | Train Loss: 0.001023
Epoch: 457 | Step 83631 | Train Loss: 0.0009518
Epoch: 458 | Step 83814 | Train Loss: 0.001026
Epoch: 459 | Step 83997 | Train Loss: 0.0009724
Epoch: 460 | Step 84000 | Valid Loss: 0.001403
Epoch: 460 | Step 84000 | Mean PER: 0.07512263679238909 | Mean WER: 0.2782978723404255
Epoch: 460 | Step 84180 | Train Loss: 0.001011
Epoch: 461 | Step 84363 | Train Loss: 0.001012
Epoch: 462 | Step 84546 | Train Loss: 0.0009954
Epoch: 463 | Step 84729 | Train Loss: 0.0009945
Epoch: 464 | Step 84912 | Train Loss: 0.001070
Epoch: 465 | Step 85095 | Train Loss: 0.001183
Epoch: 466 | Step 85278 | Train Loss: 0.001144
Epoch: 467 | Step 85461 | Train Loss: 0.001109
Epoch: 468 | Step 85644 | Train Loss: 0.001019
Epoch: 469 | Step 85827 | Train Loss: 0.001015
Epoch: 470 | Step 86000 | Valid Loss: 0.001029
Epoch: 470 | Step 86000 | Mean PER: 0.07427127393613427 | Mean WER: 0.2766808510638298
Achieving better result (mean_per): 0.07427
Epoch: 470 | Step 86010 | Train Loss: 0.001024
Epoch: 471 | Step 86193 | Train Loss: 0.001059
Epoch: 472 | Step 86376 | Train Loss: 0.001056
Epoch: 473 | Step 86559 | Train Loss: 0.001006
Epoch: 474 | Step 86742 | Train Loss: 0.001001
Epoch: 475 | Step 86925 | Train Loss: 0.0009550
Epoch: 476 | Step 87108 | Train Loss: 0.0009599
Epoch: 477 | Step 87291 | Train Loss: 0.0009396
Epoch: 478 | Step 87474 | Train Loss: 0.001119
Epoch: 479 | Step 87657 | Train Loss: 0.001012
Epoch: 480 | Step 87840 | Train Loss: 0.0009543
Epoch: 481 | Step 88000 | Valid Loss: 0.0008601
Epoch: 481 | Step 88000 | Mean PER: 0.07423073284774119 | Mean WER: 0.27574468085106385
Achieving better result (mean_per): 0.07423
Epoch: 481 | Step 88023 | Train Loss: 0.0008985
Epoch: 482 | Step 88206 | Train Loss: 0.001087
Epoch: 483 | Step 88389 | Train Loss: 0.0009864
Epoch: 484 | Step 88572 | Train Loss: 0.001085
Epoch: 485 | Step 88755 | Train Loss: 0.001036
Epoch: 486 | Step 88938 | Train Loss: 0.0009772
Epoch: 487 | Step 89121 | Train Loss: 0.001059
Epoch: 488 | Step 89304 | Train Loss: 0.0009583
Epoch: 489 | Step 89487 | Train Loss: 0.001022
Epoch: 490 | Step 89670 | Train Loss: 0.0009938
Epoch: 491 | Step 89853 | Train Loss: 0.0009026
Epoch: 492 | Step 90000 | Valid Loss: 0.0009865
Epoch: 492 | Step 90000 | Mean PER: 0.07460911633940999 | Mean WER: 0.2771063829787234
Epoch: 492 | Step 90036 | Train Loss: 0.0009693
Epoch: 493 | Step 90219 | Train Loss: 0.0009039
Epoch: 494 | Step 90402 | Train Loss: 0.0008693
Epoch: 495 | Step 90585 | Train Loss: 0.0009701
Epoch: 496 | Step 90768 | Train Loss: 0.0009749
Epoch: 497 | Step 90951 | Train Loss: 0.001019
Epoch: 498 | Step 91134 | Train Loss: 0.0009907
Epoch: 499 | Step 91317 | Train Loss: 0.001145
Epoch: 500 | Step 91500 | Train Loss: 0.001063
Epoch: 501 | Step 91683 | Train Loss: 0.001165
Epoch: 502 | Step 91866 | Train Loss: 0.001031
Epoch: 503 | Step 92000 | Valid Loss: 0.0009911
Epoch: 503 | Step 92000 | Mean PER: 0.07521723266530629 | Mean WER: 0.27974468085106385
Epoch: 503 | Step 92049 | Train Loss: 0.0009671
Epoch: 504 | Step 92232 | Train Loss: 0.0009773
Epoch: 505 | Step 92415 | Train Loss: 0.0008855
Epoch: 506 | Step 92598 | Train Loss: 0.0009286
Epoch: 507 | Step 92781 | Train Loss: 0.001061
Epoch: 508 | Step 92964 | Train Loss: 0.001031
Epoch: 509 | Step 93147 | Train Loss: 0.0009910
Epoch: 510 | Step 93330 | Train Loss: 0.0009670
Epoch: 511 | Step 93513 | Train Loss: 0.0009159
Epoch: 512 | Step 93696 | Train Loss: 0.0009873
Epoch: 513 | Step 93879 | Train Loss: 0.0009734
Epoch: 514 | Step 94000 | Valid Loss: 0.0007817
Epoch: 514 | Step 94000 | Mean PER: 0.07504155461560291 | Mean WER: 0.2782978723404255
Epoch: 514 | Step 94062 | Train Loss: 0.0009015
Epoch: 515 | Step 94245 | Train Loss: 0.0008574
Epoch: 516 | Step 94428 | Train Loss: 0.001044
Epoch: 517 | Step 94611 | Train Loss: 0.0009500
Epoch: 518 | Step 94794 | Train Loss: 0.0009545
Epoch: 519 | Step 94977 | Train Loss: 0.0009619
Epoch: 520 | Step 95160 | Train Loss: 0.0008941
Epoch: 521 | Step 95343 | Train Loss: 0.0008934
Epoch: 522 | Step 95526 | Train Loss: 0.0009149
Epoch: 523 | Step 95709 | Train Loss: 0.001069
Epoch: 524 | Step 95892 | Train Loss: 0.0009660
Epoch: 525 | Step 96000 | Valid Loss: 0.001060
Epoch: 525 | Step 96000 | Mean PER: 0.07569021202989229 | Mean WER: 0.28
Epoch: 525 | Step 96075 | Train Loss: 0.001026
Epoch: 526 | Step 96258 | Train Loss: 0.0009120
Epoch: 527 | Step 96441 | Train Loss: 0.0009999
Epoch: 528 | Step 96624 | Train Loss: 0.001159
Epoch: 529 | Step 96807 | Train Loss: 0.001000
Epoch: 530 | Step 96990 | Train Loss: 0.001015
Epoch: 531 | Step 97173 | Train Loss: 0.0009438
Epoch: 532 | Step 97356 | Train Loss: 0.0008744
Epoch: 533 | Step 97539 | Train Loss: 0.0009079
Epoch: 534 | Step 97722 | Train Loss: 0.0008449
Epoch: 535 | Step 97905 | Train Loss: 0.0009565
Epoch: 536 | Step 98000 | Valid Loss: 0.0007712
Epoch: 536 | Step 98000 | Mean PER: 0.07433884241678941 | Mean WER: 0.2771914893617021
Epoch: 536 | Step 98088 | Train Loss: 0.0009563
Epoch: 537 | Step 98271 | Train Loss: 0.0009000
Epoch: 538 | Step 98454 | Train Loss: 0.0008812
Epoch: 539 | Step 98637 | Train Loss: 0.0009535
Epoch: 540 | Step 98820 | Train Loss: 0.0009395
Epoch: 541 | Step 99003 | Train Loss: 0.0009856
Epoch: 542 | Step 99186 | Train Loss: 0.0009501
Epoch: 543 | Step 99369 | Train Loss: 0.0008750
Epoch: 544 | Step 99552 | Train Loss: 0.0009241
Epoch: 545 | Step 99735 | Train Loss: 0.0008949
Epoch: 546 | Step 99918 | Train Loss: 0.0008286
Epoch: 547 | Step 100000 | Valid Loss: 0.0008942
Epoch: 547 | Step 100000 | Mean PER: 0.07440641089744456 | Mean WER: 0.2771914893617021
Epoch: 547 | Step 100101 | Train Loss: 0.0008830
Epoch: 548 | Step 100284 | Train Loss: 0.0007982
Epoch: 549 | Step 100467 | Train Loss: 0.0007134
Epoch: 550 | Step 100650 | Train Loss: 0.0006094
Epoch: 551 | Step 100833 | Train Loss: 0.0005758
Epoch: 552 | Step 101016 | Train Loss: 0.0006075
Epoch: 553 | Step 101199 | Train Loss: 0.0006148
Epoch: 554 | Step 101382 | Train Loss: 0.0004862
Epoch: 555 | Step 101565 | Train Loss: 0.0004953
Epoch: 556 | Step 101748 | Train Loss: 0.0005628
Epoch: 557 | Step 101931 | Train Loss: 0.0005551
Epoch: 558 | Step 102000 | Valid Loss: 0.0005835
Epoch: 558 | Step 102000 | Mean PER: 0.07436586980905148 | Mean WER: 0.27693617021276595
Epoch: 558 | Step 102114 | Train Loss: 0.0006114
Epoch: 559 | Step 102297 | Train Loss: 0.0005617
Epoch: 560 | Step 102480 | Train Loss: 0.0005269
Epoch: 561 | Step 102663 | Train Loss: 0.0005923
Epoch: 562 | Step 102846 | Train Loss: 0.0005404
Epoch: 563 | Step 103029 | Train Loss: 0.0004888
Epoch: 564 | Step 103212 | Train Loss: 0.0005100
Epoch: 565 | Step 103395 | Train Loss: 0.0004930
Epoch: 566 | Step 103578 | Train Loss: 0.0004766
Epoch: 567 | Step 103761 | Train Loss: 0.0005371
Epoch: 568 | Step 103944 | Train Loss: 0.0004834
Epoch: 569 | Step 104000 | Valid Loss: 0.0004658
Epoch: 569 | Step 104000 | Mean PER: 0.07479830808524439 | Mean WER: 0.278468085106383
Epoch: 569 | Step 104127 | Train Loss: 0.0005131
Epoch: 570 | Step 104310 | Train Loss: 0.0005305
Epoch: 571 | Step 104493 | Train Loss: 0.0005782
Epoch: 572 | Step 104676 | Train Loss: 0.0005852
Epoch: 573 | Step 104859 | Train Loss: 0.0004987
Epoch: 574 | Step 105042 | Train Loss: 0.0005251
Epoch: 575 | Step 105225 | Train Loss: 0.0005485
Epoch: 576 | Step 105408 | Train Loss: 0.0005217
Epoch: 577 | Step 105591 | Train Loss: 0.0005283
Epoch: 578 | Step 105774 | Train Loss: 0.0004947
Epoch: 579 | Step 105957 | Train Loss: 0.0005068
Epoch: 580 | Step 106000 | Valid Loss: 0.0004385
Epoch: 580 | Step 106000 | Mean PER: 0.07477128069298233 | Mean WER: 0.27582978723404256
Epoch: 580 | Step 106140 | Train Loss: 0.0004778
Epoch: 581 | Step 106323 | Train Loss: 0.0004366
Epoch: 582 | Step 106506 | Train Loss: 0.0004821
Epoch: 583 | Step 106689 | Train Loss: 0.0004534
Epoch: 584 | Step 106872 | Train Loss: 0.0004209
Epoch: 585 | Step 107055 | Train Loss: 0.0004914
Epoch: 586 | Step 107238 | Train Loss: 0.0005017
Epoch: 587 | Step 107421 | Train Loss: 0.0004299
Epoch: 588 | Step 107604 | Train Loss: 0.0004920
Epoch: 589 | Step 107787 | Train Loss: 0.0004378
Epoch: 590 | Step 107970 | Train Loss: 0.0003786
Epoch: 591 | Step 108000 | Valid Loss: 0.0004310
Epoch: 591 | Step 108000 | Mean PER: 0.07425776024000325 | Mean WER: 0.2756595744680851
Epoch: 591 | Step 108153 | Train Loss: 0.0005073
Epoch: 592 | Step 108336 | Train Loss: 0.0004480
Epoch: 593 | Step 108519 | Train Loss: 0.0003909
Epoch: 594 | Step 108702 | Train Loss: 0.0004210
Epoch: 595 | Step 108885 | Train Loss: 0.0004852
Epoch: 596 | Step 109068 | Train Loss: 0.0004344
Epoch: 597 | Step 109251 | Train Loss: 0.0004670
Epoch: 598 | Step 109434 | Train Loss: 0.0004147
Epoch: 599 | Step 109617 | Train Loss: 0.0005260
Epoch: 600 | Step 109800 | Train Loss: 0.0004550
Epoch: 601 | Step 109983 | Train Loss: 0.0004014
Epoch: 602 | Step 110000 | Valid Loss: 0.0002964
Epoch: 602 | Step 110000 | Mean PER: 0.07424424654387221 | Mean WER: 0.27591489361702126
Epoch: 602 | Step 110166 | Train Loss: 0.0004304
Epoch: 603 | Step 110349 | Train Loss: 0.0003971
Epoch: 604 | Step 110532 | Train Loss: 0.0004224
Epoch: 605 | Step 110715 | Train Loss: 0.0004049
Epoch: 606 | Step 110898 | Train Loss: 0.0004268
Epoch: 607 | Step 111081 | Train Loss: 0.0003574
Epoch: 608 | Step 111264 | Train Loss: 0.0004242
Epoch: 609 | Step 111447 | Train Loss: 0.0004177
Epoch: 610 | Step 111630 | Train Loss: 0.0003991
Epoch: 611 | Step 111813 | Train Loss: 0.0004650
