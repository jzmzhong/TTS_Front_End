GBERT(
  (embedding): Embedding(32, 512)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (fc_out): Linear(in_features=512, out_features=31, bias=True)
)
Training on device: cuda
GBERT(
  (embedding): Embedding(32, 512)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (fc_out): Linear(in_features=512, out_features=31, bias=True)
)
Training on device: cuda
Epoch: 946 | Step 276292 | Train Loss: 3.127
GBERT(
  (embedding): Embedding(32, 512)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (fc_out): Linear(in_features=512, out_features=31, bias=True)
)
Training on device: cuda
Epoch: 946 | Step 276292 | Train Loss: 0.3107
Epoch: 947 | Step 276584 | Train Loss: 0.3086
Epoch: 948 | Step 276876 | Train Loss: 0.3067
Epoch: 949 | Step 277168 | Train Loss: 0.3057
Epoch: 950 | Step 277460 | Train Loss: 0.3040
Epoch: 951 | Step 277752 | Train Loss: 0.3094
Epoch: 952 | Step 278000 | Valid Loss: 0.3087
Epoch: 952 | Step 278000 | Mean Mask Error Rate: 0.3671663145286064
Epoch: 952 | Step 278044 | Train Loss: 0.3076
Epoch: 953 | Step 278336 | Train Loss: 0.3058
Epoch: 954 | Step 278628 | Train Loss: 0.3043
Epoch: 955 | Step 278920 | Train Loss: 0.3032
Epoch: 956 | Step 279212 | Train Loss: 0.3018
Epoch: 957 | Step 279504 | Train Loss: 0.3004
Epoch: 958 | Step 279796 | Train Loss: 0.2993
Epoch: 959 | Step 280000 | Valid Loss: 0.3009
Epoch: 959 | Step 280000 | Mean Mask Error Rate: 0.36798565938544975
Epoch: 959 | Step 280088 | Train Loss: 0.2980
Epoch: 960 | Step 280380 | Train Loss: 0.2970
Epoch: 961 | Step 280672 | Train Loss: 0.3111
Epoch: 962 | Step 280964 | Train Loss: 0.3091
Epoch: 963 | Step 281256 | Train Loss: 0.3074
Epoch: 964 | Step 281548 | Train Loss: 0.3057
Epoch: 965 | Step 281840 | Train Loss: 0.3044
Epoch: 966 | Step 282000 | Valid Loss: 0.2979
Epoch: 966 | Step 282000 | Mean Mask Error Rate: 0.3675739074015538
Epoch: 966 | Step 282132 | Train Loss: 0.3031
Epoch: 967 | Step 282424 | Train Loss: 0.3018
Epoch: 968 | Step 282716 | Train Loss: 0.3006
Epoch: 969 | Step 283008 | Train Loss: 0.2997
Epoch: 970 | Step 283300 | Train Loss: 0.2980
Epoch: 971 | Step 283592 | Train Loss: 0.3103
Epoch: 972 | Step 283884 | Train Loss: 0.3082
Epoch: 973 | Step 284000 | Valid Loss: 0.3013
Epoch: 973 | Step 284000 | Mean Mask Error Rate: 0.36710808697532815
Epoch: 973 | Step 284176 | Train Loss: 0.3068
Epoch: 974 | Step 284468 | Train Loss: 0.3052
Epoch: 975 | Step 284760 | Train Loss: 0.3037
Epoch: 976 | Step 285052 | Train Loss: 0.3024
Epoch: 977 | Step 285344 | Train Loss: 0.3015
Epoch: 978 | Step 285636 | Train Loss: 0.3000
Epoch: 979 | Step 285928 | Train Loss: 0.2985
Epoch: 980 | Step 286000 | Valid Loss: 0.3106
Epoch: 980 | Step 286000 | Mean Mask Error Rate: 0.36877173135470565
Epoch: 980 | Step 286220 | Train Loss: 0.2976
Epoch: 981 | Step 286512 | Train Loss: 0.3093
Epoch: 982 | Step 286804 | Train Loss: 0.3072
Epoch: 983 | Step 287096 | Train Loss: 0.3055
Epoch: 984 | Step 287388 | Train Loss: 0.3041
Epoch: 985 | Step 287680 | Train Loss: 0.3025
Epoch: 986 | Step 287972 | Train Loss: 0.3011
Epoch: 987 | Step 288000 | Valid Loss: 0.3169
Epoch: 987 | Step 288000 | Mean Mask Error Rate: 0.3675323162920694
Epoch: 987 | Step 288264 | Train Loss: 0.2999
Epoch: 988 | Step 288556 | Train Loss: 0.2987
Epoch: 989 | Step 288848 | Train Loss: 0.2979
Epoch: 990 | Step 289140 | Train Loss: 0.2963
Epoch: 991 | Step 289432 | Train Loss: 0.3091
Epoch: 992 | Step 289724 | Train Loss: 0.3068
Epoch: 993 | Step 290000 | Valid Loss: 0.3046
Epoch: 993 | Step 290000 | Mean Mask Error Rate: 0.3671704736395548
Epoch: 993 | Step 290016 | Train Loss: 0.3050
Epoch: 994 | Step 290308 | Train Loss: 0.3035
Epoch: 995 | Step 290600 | Train Loss: 0.3023
Epoch: 996 | Step 290892 | Train Loss: 0.3009
Epoch: 997 | Step 291184 | Train Loss: 0.2997
Epoch: 998 | Step 291476 | Train Loss: 0.2984
Epoch: 999 | Step 291768 | Train Loss: 0.2971
Epoch: 1000 | Step 292000 | Valid Loss: 0.2948
Epoch: 1000 | Step 292000 | Mean Mask Error Rate: 0.3679107953883778
Epoch: 1000 | Step 292060 | Train Loss: 0.2961
GBERT(
  (embedding): Embedding(32, 512)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (fc_out): Linear(in_features=512, out_features=31, bias=True)
)
Training on device: cuda
Epoch: 946 | Step 276292 | Train Loss: 0.3116
Epoch: 947 | Step 276584 | Train Loss: 0.3096
Epoch: 948 | Step 276876 | Train Loss: 0.3081
Epoch: 949 | Step 277168 | Train Loss: 0.3064
Epoch: 950 | Step 277460 | Train Loss: 0.3050
Epoch: 951 | Step 277752 | Train Loss: 0.3099
Epoch: 952 | Step 278000 | Valid Loss: 0.3090
GBERT(
  (embedding): Embedding(32, 512)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (fc_out): Linear(in_features=512, out_features=31, bias=True)
)
Training on device: cuda
Epoch: 1001 | Step 292292 | Train Loss: 0.3105
Epoch: 1002 | Step 292584 | Train Loss: 0.3082
Epoch: 1003 | Step 292876 | Train Loss: 0.3064
Epoch: 1004 | Step 293168 | Train Loss: 0.3050
Epoch: 1005 | Step 293460 | Train Loss: 0.3038
Epoch: 1006 | Step 293752 | Train Loss: 0.3024
Epoch: 1007 | Step 294000 | Valid Loss: 0.3016
Epoch: 1007 | Step 294000 | Mean Mask Error Rate: 0.3667795172104011
Epoch: 1007 | Step 294044 | Train Loss: 0.3010
Epoch: 1008 | Step 294336 | Train Loss: 0.3001
Epoch: 1009 | Step 294628 | Train Loss: 0.2987
Epoch: 1010 | Step 294920 | Train Loss: 0.2974
Epoch: 1011 | Step 295212 | Train Loss: 0.3095
Epoch: 1012 | Step 295504 | Train Loss: 0.3074
Epoch: 1013 | Step 295796 | Train Loss: 0.3060
Epoch: 1014 | Step 296000 | Valid Loss: 0.2984
Epoch: 1014 | Step 296000 | Mean Mask Error Rate: 0.3663303332279692
Epoch: 1014 | Step 296088 | Train Loss: 0.3040
Epoch: 1015 | Step 296380 | Train Loss: 0.3026
Epoch: 1016 | Step 296672 | Train Loss: 0.3013
Epoch: 1017 | Step 296964 | Train Loss: 0.3002
Epoch: 1018 | Step 297256 | Train Loss: 0.2991
Epoch: 1019 | Step 297548 | Train Loss: 0.2976
Epoch: 1020 | Step 297840 | Train Loss: 0.2964
Epoch: 1021 | Step 298000 | Valid Loss: 0.3047
Epoch: 1021 | Step 298000 | Mean Mask Error Rate: 0.3665965163286696
Epoch: 1021 | Step 298132 | Train Loss: 0.3093
Epoch: 1022 | Step 298424 | Train Loss: 0.3069
Epoch: 1023 | Step 298716 | Train Loss: 0.3056
Epoch: 1024 | Step 299008 | Train Loss: 0.3039
Epoch: 1025 | Step 299300 | Train Loss: 0.3023
Epoch: 1026 | Step 299592 | Train Loss: 0.3011
Epoch: 1027 | Step 299884 | Train Loss: 0.3000
Epoch: 1028 | Step 300000 | Valid Loss: 0.3056
Epoch: 1028 | Step 300000 | Mean Mask Error Rate: 0.36710808697532815
Epoch: 1028 | Step 300176 | Train Loss: 0.2989
Epoch: 1029 | Step 300468 | Train Loss: 0.2977
Epoch: 1030 | Step 300760 | Train Loss: 0.2963
Epoch: 1031 | Step 301052 | Train Loss: 0.3100
Epoch: 1032 | Step 301344 | Train Loss: 0.3078
Epoch: 1033 | Step 301636 | Train Loss: 0.3062
Epoch: 1034 | Step 301928 | Train Loss: 0.3046
Epoch: 1035 | Step 302000 | Valid Loss: 0.2890
Epoch: 1035 | Step 302000 | Mean Mask Error Rate: 0.3664509474454741
Epoch: 1035 | Step 302220 | Train Loss: 0.3035
Epoch: 1036 | Step 302512 | Train Loss: 0.3019
Epoch: 1037 | Step 302804 | Train Loss: 0.3006
Epoch: 1038 | Step 303096 | Train Loss: 0.2996
Epoch: 1039 | Step 303388 | Train Loss: 0.2983
Epoch: 1040 | Step 303680 | Train Loss: 0.2972
Epoch: 1041 | Step 303972 | Train Loss: 0.3094
Epoch: 1042 | Step 304000 | Valid Loss: 0.2939
Epoch: 1042 | Step 304000 | Mean Mask Error Rate: 0.3663594470046083
Epoch: 1042 | Step 304264 | Train Loss: 0.3075
Epoch: 1043 | Step 304556 | Train Loss: 0.3054
Epoch: 1044 | Step 304848 | Train Loss: 0.3040
Epoch: 1045 | Step 305140 | Train Loss: 0.3026
Epoch: 1046 | Step 305432 | Train Loss: 0.3014
Epoch: 1047 | Step 305724 | Train Loss: 0.3001
Epoch: 1048 | Step 306000 | Valid Loss: 0.2975
Epoch: 1048 | Step 306000 | Mean Mask Error Rate: 0.36709976875343125
Epoch: 1048 | Step 306016 | Train Loss: 0.2986
Epoch: 1049 | Step 306308 | Train Loss: 0.2975
Epoch: 1050 | Step 306600 | Train Loss: 0.2965
Epoch: 1051 | Step 306892 | Train Loss: 0.3101
Epoch: 1052 | Step 307184 | Train Loss: 0.3080
Epoch: 1053 | Step 307476 | Train Loss: 0.3064
Epoch: 1054 | Step 307768 | Train Loss: 0.3049
Epoch: 1055 | Step 308000 | Valid Loss: 0.3042
Epoch: 1055 | Step 308000 | Mean Mask Error Rate: 0.3659809679082999
Epoch: 1055 | Step 308060 | Train Loss: 0.3036
Epoch: 1056 | Step 308352 | Train Loss: 0.3021
Epoch: 1057 | Step 308644 | Train Loss: 0.3008
Epoch: 1058 | Step 308936 | Train Loss: 0.2997
Epoch: 1059 | Step 309228 | Train Loss: 0.2983
Epoch: 1060 | Step 309520 | Train Loss: 0.2975
Epoch: 1061 | Step 309812 | Train Loss: 0.3099
Epoch: 1062 | Step 310000 | Valid Loss: 0.3098
Epoch: 1062 | Step 310000 | Mean Mask Error Rate: 0.3660891047929595
Epoch: 1062 | Step 310104 | Train Loss: 0.3078
Epoch: 1063 | Step 310396 | Train Loss: 0.3060
Epoch: 1064 | Step 310688 | Train Loss: 0.3046
Epoch: 1065 | Step 310980 | Train Loss: 0.3032
Epoch: 1066 | Step 311272 | Train Loss: 0.3013
Epoch: 1067 | Step 311564 | Train Loss: 0.3003
Epoch: 1068 | Step 311856 | Train Loss: 0.2991
Epoch: 1069 | Step 312000 | Valid Loss: 0.2911
Epoch: 1069 | Step 312000 | Mean Mask Error Rate: 0.3664800612221132
Epoch: 1069 | Step 312148 | Train Loss: 0.2979
Epoch: 1070 | Step 312440 | Train Loss: 0.2969
Epoch: 1071 | Step 312732 | Train Loss: 0.3082
Epoch: 1072 | Step 313024 | Train Loss: 0.3064
Epoch: 1073 | Step 313316 | Train Loss: 0.3045
Epoch: 1074 | Step 313608 | Train Loss: 0.3029
Epoch: 1075 | Step 313900 | Train Loss: 0.3020
Epoch: 1076 | Step 314000 | Valid Loss: 0.2876
Epoch: 1076 | Step 314000 | Mean Mask Error Rate: 0.36662147099436027
Epoch: 1076 | Step 314192 | Train Loss: 0.3003
Epoch: 1077 | Step 314484 | Train Loss: 0.2991
Epoch: 1078 | Step 314776 | Train Loss: 0.2979
Epoch: 1079 | Step 315068 | Train Loss: 0.2963
Epoch: 1080 | Step 315360 | Train Loss: 0.2952
Epoch: 1081 | Step 315652 | Train Loss: 0.3088
Epoch: 1082 | Step 315944 | Train Loss: 0.3064
Epoch: 1083 | Step 316000 | Valid Loss: 0.3169
Epoch: 1083 | Step 316000 | Mean Mask Error Rate: 0.3664717430002163
Epoch: 1083 | Step 316236 | Train Loss: 0.3049
Epoch: 1084 | Step 316528 | Train Loss: 0.3033
Epoch: 1085 | Step 316820 | Train Loss: 0.3019
Epoch: 1086 | Step 317112 | Train Loss: 0.3005
Epoch: 1087 | Step 317404 | Train Loss: 0.2989
Epoch: 1088 | Step 317696 | Train Loss: 0.2976
Epoch: 1089 | Step 317988 | Train Loss: 0.2969
Epoch: 1090 | Step 318000 | Valid Loss: 0.2450
Epoch: 1090 | Step 318000 | Mean Mask Error Rate: 0.3665881981067727
Epoch: 1090 | Step 318280 | Train Loss: 0.2960
Epoch: 1091 | Step 318572 | Train Loss: 0.3089
Epoch: 1092 | Step 318864 | Train Loss: 0.3068
Epoch: 1093 | Step 319156 | Train Loss: 0.3051
Epoch: 1094 | Step 319448 | Train Loss: 0.3035
Epoch: 1095 | Step 319740 | Train Loss: 0.3023
Epoch: 1096 | Step 320000 | Valid Loss: 0.2952
Epoch: 1096 | Step 320000 | Mean Mask Error Rate: 0.36651749322064914
Epoch: 1096 | Step 320032 | Train Loss: 0.3008
Epoch: 1097 | Step 320324 | Train Loss: 0.2992
Epoch: 1098 | Step 320616 | Train Loss: 0.2986
Epoch: 1099 | Step 320908 | Train Loss: 0.2979
Epoch: 1100 | Step 321200 | Train Loss: 0.2973
Epoch: 1101 | Step 321492 | Train Loss: 0.3082
Epoch: 1102 | Step 321784 | Train Loss: 0.3072
Epoch: 1103 | Step 322000 | Valid Loss: 0.3018
Epoch: 1103 | Step 322000 | Mean Mask Error Rate: 0.36544028348500224
Epoch: 1103 | Step 322076 | Train Loss: 0.3063
Epoch: 1104 | Step 322368 | Train Loss: 0.3051
Epoch: 1105 | Step 322660 | Train Loss: 0.3042
Epoch: 1106 | Step 322952 | Train Loss: 0.3035
Epoch: 1107 | Step 323244 | Train Loss: 0.3026
Epoch: 1108 | Step 323536 | Train Loss: 0.3017
Epoch: 1109 | Step 323828 | Train Loss: 0.3012
Epoch: 1110 | Step 324000 | Valid Loss: 0.3017
Epoch: 1110 | Step 324000 | Mean Mask Error Rate: 0.36559417059009464
Epoch: 1110 | Step 324120 | Train Loss: 0.3004
Epoch: 1111 | Step 324412 | Train Loss: 0.3082
Epoch: 1112 | Step 324704 | Train Loss: 0.3070
Epoch: 1113 | Step 324996 | Train Loss: 0.3060
Epoch: 1114 | Step 325288 | Train Loss: 0.3053
Epoch: 1115 | Step 325580 | Train Loss: 0.3042
Epoch: 1116 | Step 325872 | Train Loss: 0.3036
Epoch: 1117 | Step 326000 | Valid Loss: 0.2976
Epoch: 1117 | Step 326000 | Mean Mask Error Rate: 0.36507844083248764
Epoch: 1117 | Step 326164 | Train Loss: 0.3026
Epoch: 1118 | Step 326456 | Train Loss: 0.3021
Epoch: 1119 | Step 326748 | Train Loss: 0.3014
Epoch: 1120 | Step 327040 | Train Loss: 0.3007
Epoch: 1121 | Step 327332 | Train Loss: 0.3074
Epoch: 1122 | Step 327624 | Train Loss: 0.3062
Epoch: 1123 | Step 327916 | Train Loss: 0.3054
Epoch: 1124 | Step 328000 | Valid Loss: 0.2906
Epoch: 1124 | Step 328000 | Mean Mask Error Rate: 0.3649703039478281
Epoch: 1124 | Step 328208 | Train Loss: 0.3044
Epoch: 1125 | Step 328500 | Train Loss: 0.3038
Epoch: 1126 | Step 328792 | Train Loss: 0.3024
Epoch: 1127 | Step 329084 | Train Loss: 0.3016
Epoch: 1128 | Step 329376 | Train Loss: 0.3012
Epoch: 1129 | Step 329668 | Train Loss: 0.3002
Epoch: 1130 | Step 329960 | Train Loss: 0.2999
Epoch: 1131 | Step 330000 | Valid Loss: 0.3019
Epoch: 1131 | Step 330000 | Mean Mask Error Rate: 0.3654361243740538
Epoch: 1131 | Step 330252 | Train Loss: 0.3069
Epoch: 1132 | Step 330544 | Train Loss: 0.3059
Epoch: 1133 | Step 330836 | Train Loss: 0.3051
Epoch: 1134 | Step 331128 | Train Loss: 0.3038
Epoch: 1135 | Step 331420 | Train Loss: 0.3033
Epoch: 1136 | Step 331712 | Train Loss: 0.3023
Epoch: 1137 | Step 332000 | Valid Loss: 0.3017
Epoch: 1137 | Step 332000 | Mean Mask Error Rate: 0.36497446305877657
Epoch: 1137 | Step 332004 | Train Loss: 0.3017
Epoch: 1138 | Step 332296 | Train Loss: 0.3009
Epoch: 1139 | Step 332588 | Train Loss: 0.3000
Epoch: 1140 | Step 332880 | Train Loss: 0.2995
Epoch: 1141 | Step 333172 | Train Loss: 0.3060
Epoch: 1142 | Step 333464 | Train Loss: 0.3047
Epoch: 1143 | Step 333756 | Train Loss: 0.3039
Epoch: 1144 | Step 334000 | Valid Loss: 0.2956
Epoch: 1144 | Step 334000 | Mean Mask Error Rate: 0.364828894175581
Epoch: 1144 | Step 334048 | Train Loss: 0.3029
Epoch: 1145 | Step 334340 | Train Loss: 0.3023
Epoch: 1146 | Step 334632 | Train Loss: 0.3013
Epoch: 1147 | Step 334924 | Train Loss: 0.3006
Epoch: 1148 | Step 335216 | Train Loss: 0.3000
Epoch: 1149 | Step 335508 | Train Loss: 0.2993
Epoch: 1150 | Step 335800 | Train Loss: 0.2986
Epoch: 1151 | Step 336000 | Valid Loss: 0.3088
Epoch: 1151 | Step 336000 | Mean Mask Error Rate: 0.36487048528506544
Epoch: 1151 | Step 336092 | Train Loss: 0.3051
Epoch: 1152 | Step 336384 | Train Loss: 0.3042
Epoch: 1153 | Step 336676 | Train Loss: 0.3032
Epoch: 1154 | Step 336968 | Train Loss: 0.3023
Epoch: 1155 | Step 337260 | Train Loss: 0.3014
Epoch: 1156 | Step 337552 | Train Loss: 0.3005
Epoch: 1157 | Step 337844 | Train Loss: 0.2998
Epoch: 1158 | Step 338000 | Valid Loss: 0.3084
Epoch: 1158 | Step 338000 | Mean Mask Error Rate: 0.36472907551281836
Epoch: 1158 | Step 338136 | Train Loss: 0.2989
Epoch: 1159 | Step 338428 | Train Loss: 0.2985
Epoch: 1160 | Step 338720 | Train Loss: 0.2979
Epoch: 1161 | Step 339012 | Train Loss: 0.3063
Epoch: 1162 | Step 339304 | Train Loss: 0.3053
Epoch: 1163 | Step 339596 | Train Loss: 0.3041
Epoch: 1164 | Step 339888 | Train Loss: 0.3033
Epoch: 1165 | Step 340000 | Valid Loss: 0.3042
Epoch: 1165 | Step 340000 | Mean Mask Error Rate: 0.3646833252923855
Epoch: 1165 | Step 340180 | Train Loss: 0.3027
Epoch: 1166 | Step 340472 | Train Loss: 0.3017
Epoch: 1167 | Step 340764 | Train Loss: 0.3011
Epoch: 1168 | Step 341056 | Train Loss: 0.3004
Epoch: 1169 | Step 341348 | Train Loss: 0.2998
Epoch: 1170 | Step 341640 | Train Loss: 0.2990
Epoch: 1171 | Step 341932 | Train Loss: 0.3064
Epoch: 1172 | Step 342000 | Valid Loss: 0.2943
Epoch: 1172 | Step 342000 | Mean Mask Error Rate: 0.36453775640918995
Epoch: 1172 | Step 342224 | Train Loss: 0.3057
Epoch: 1173 | Step 342516 | Train Loss: 0.3047
Epoch: 1174 | Step 342808 | Train Loss: 0.3037
Epoch: 1175 | Step 343100 | Train Loss: 0.3028
Epoch: 1176 | Step 343392 | Train Loss: 0.3020
Epoch: 1177 | Step 343684 | Train Loss: 0.3015
Epoch: 1178 | Step 343976 | Train Loss: 0.3007
Epoch: 1179 | Step 344000 | Valid Loss: 0.2918
Epoch: 1179 | Step 344000 | Mean Mask Error Rate: 0.3644337786354789
Epoch: 1179 | Step 344268 | Train Loss: 0.3003
Epoch: 1180 | Step 344560 | Train Loss: 0.2992
Epoch: 1181 | Step 344852 | Train Loss: 0.3068
Epoch: 1182 | Step 345144 | Train Loss: 0.3057
Epoch: 1183 | Step 345436 | Train Loss: 0.3049
Epoch: 1184 | Step 345728 | Train Loss: 0.3041
Epoch: 1185 | Step 346000 | Valid Loss: 0.3049
Epoch: 1185 | Step 346000 | Mean Mask Error Rate: 0.3639388444326141
Epoch: 1185 | Step 346020 | Train Loss: 0.3034
Epoch: 1186 | Step 346312 | Train Loss: 0.3021
Epoch: 1187 | Step 346604 | Train Loss: 0.3016
Epoch: 1188 | Step 346896 | Train Loss: 0.3007
Epoch: 1189 | Step 347188 | Train Loss: 0.3003
Epoch: 1190 | Step 347480 | Train Loss: 0.2994
Epoch: 1191 | Step 347772 | Train Loss: 0.3055
Epoch: 1192 | Step 348000 | Valid Loss: 0.3060
Epoch: 1192 | Step 348000 | Mean Mask Error Rate: 0.3644420968573758
Epoch: 1192 | Step 348064 | Train Loss: 0.3041
Epoch: 1193 | Step 348356 | Train Loss: 0.3035
Epoch: 1194 | Step 348648 | Train Loss: 0.3024
Epoch: 1195 | Step 348940 | Train Loss: 0.3017
Epoch: 1196 | Step 349232 | Train Loss: 0.3006
Epoch: 1197 | Step 349524 | Train Loss: 0.2999
Epoch: 1198 | Step 349816 | Train Loss: 0.2994
Epoch: 1199 | Step 350000 | Valid Loss: 0.3033
Epoch: 1199 | Step 350000 | Mean Mask Error Rate: 0.3647207572909215
Epoch: 1199 | Step 350108 | Train Loss: 0.2986
Epoch: 1200 | Step 350400 | Train Loss: 0.2978
Epoch: 1201 | Step 350692 | Train Loss: 0.3063
Epoch: 1202 | Step 350984 | Train Loss: 0.3053
Epoch: 1203 | Step 351276 | Train Loss: 0.3044
Epoch: 1204 | Step 351568 | Train Loss: 0.3037
Epoch: 1205 | Step 351860 | Train Loss: 0.3026
Epoch: 1206 | Step 352000 | Valid Loss: 0.2953
Epoch: 1206 | Step 352000 | Mean Mask Error Rate: 0.3639263670997688
Epoch: 1206 | Step 352152 | Train Loss: 0.3021
Epoch: 1207 | Step 352444 | Train Loss: 0.3014
Epoch: 1208 | Step 352736 | Train Loss: 0.3003
Epoch: 1209 | Step 353028 | Train Loss: 0.2999
Epoch: 1210 | Step 353320 | Train Loss: 0.2991
Epoch: 1211 | Step 353612 | Train Loss: 0.3066
Epoch: 1212 | Step 353904 | Train Loss: 0.3056
Epoch: 1213 | Step 354000 | Valid Loss: 0.3044
Epoch: 1213 | Step 354000 | Mean Mask Error Rate: 0.3641800728676238
Epoch: 1213 | Step 354196 | Train Loss: 0.3046
Epoch: 1214 | Step 354488 | Train Loss: 0.3035
Epoch: 1215 | Step 354780 | Train Loss: 0.3030
Epoch: 1216 | Step 355072 | Train Loss: 0.3020
Epoch: 1217 | Step 355364 | Train Loss: 0.3015
Epoch: 1218 | Step 355656 | Train Loss: 0.3004
Epoch: 1219 | Step 355948 | Train Loss: 0.2998
Epoch: 1220 | Step 356000 | Valid Loss: 0.2900
Epoch: 1220 | Step 356000 | Mean Mask Error Rate: 0.36442961952453046
Epoch: 1220 | Step 356240 | Train Loss: 0.2995
Epoch: 1221 | Step 356532 | Train Loss: 0.3069
Epoch: 1222 | Step 356824 | Train Loss: 0.3057
Epoch: 1223 | Step 357116 | Train Loss: 0.3046
Epoch: 1224 | Step 357408 | Train Loss: 0.3038
Epoch: 1225 | Step 357700 | Train Loss: 0.3033
Epoch: 1226 | Step 357992 | Train Loss: 0.3024
Epoch: 1227 | Step 358000 | Valid Loss: 0.3204
Epoch: 1227 | Step 358000 | Mean Mask Error Rate: 0.3639430035435625
Epoch: 1227 | Step 358284 | Train Loss: 0.3012
Epoch: 1228 | Step 358576 | Train Loss: 0.3013
Epoch: 1229 | Step 358868 | Train Loss: 0.3007
Epoch: 1230 | Step 359160 | Train Loss: 0.3003
Epoch: 1231 | Step 359452 | Train Loss: 0.3045
Epoch: 1232 | Step 359744 | Train Loss: 0.3037
Epoch: 1233 | Step 360000 | Valid Loss: 0.2995
Epoch: 1233 | Step 360000 | Mean Mask Error Rate: 0.36330250045750223
Epoch: 1233 | Step 360036 | Train Loss: 0.3033
Epoch: 1234 | Step 360328 | Train Loss: 0.3028
Epoch: 1235 | Step 360620 | Train Loss: 0.3026
Epoch: 1236 | Step 360912 | Train Loss: 0.3017
Epoch: 1237 | Step 361204 | Train Loss: 0.3015
Epoch: 1238 | Step 361496 | Train Loss: 0.3012
Epoch: 1239 | Step 361788 | Train Loss: 0.3005
Epoch: 1240 | Step 362000 | Valid Loss: 0.3009
Epoch: 1240 | Step 362000 | Mean Mask Error Rate: 0.3637308888851919
Epoch: 1240 | Step 362080 | Train Loss: 0.3004
Epoch: 1241 | Step 362372 | Train Loss: 0.3063
Epoch: 1242 | Step 362664 | Train Loss: 0.3054
Epoch: 1243 | Step 362956 | Train Loss: 0.3052
Epoch: 1244 | Step 363248 | Train Loss: 0.3047
Epoch: 1245 | Step 363540 | Train Loss: 0.3044
Epoch: 1246 | Step 363832 | Train Loss: 0.3039
Epoch: 1247 | Step 364000 | Valid Loss: 0.3066
Epoch: 1247 | Step 364000 | Mean Mask Error Rate: 0.363797434660367
Epoch: 1247 | Step 364124 | Train Loss: 0.3032
Epoch: 1248 | Step 364416 | Train Loss: 0.3028
Epoch: 1249 | Step 364708 | Train Loss: 0.3023
Epoch: 1250 | Step 365000 | Train Loss: 0.3021
Epoch: 1251 | Step 365292 | Train Loss: 0.3049
Epoch: 1252 | Step 365584 | Train Loss: 0.3043
Epoch: 1253 | Step 365876 | Train Loss: 0.3040
Epoch: 1254 | Step 366000 | Valid Loss: 0.2866
Epoch: 1254 | Step 366000 | Mean Mask Error Rate: 0.36334409156698666
Epoch: 1254 | Step 366168 | Train Loss: 0.3033
Epoch: 1255 | Step 366460 | Train Loss: 0.3029
Epoch: 1256 | Step 366752 | Train Loss: 0.3025
Epoch: 1257 | Step 367044 | Train Loss: 0.3020
Epoch: 1258 | Step 367336 | Train Loss: 0.3018
Epoch: 1259 | Step 367628 | Train Loss: 0.3009
Epoch: 1260 | Step 367920 | Train Loss: 0.3008
Epoch: 1261 | Step 368000 | Valid Loss: 0.2833
Epoch: 1261 | Step 368000 | Mean Mask Error Rate: 0.363394000898368
Epoch: 1261 | Step 368212 | Train Loss: 0.3067
Epoch: 1262 | Step 368504 | Train Loss: 0.3060
Epoch: 1263 | Step 368796 | Train Loss: 0.3054
Epoch: 1264 | Step 369088 | Train Loss: 0.3049
Epoch: 1265 | Step 369380 | Train Loss: 0.3046
Epoch: 1266 | Step 369672 | Train Loss: 0.3038
Epoch: 1267 | Step 369964 | Train Loss: 0.3038
Epoch: 1268 | Step 370000 | Valid Loss: 0.3107
Epoch: 1268 | Step 370000 | Mean Mask Error Rate: 0.36334409156698666
Epoch: 1268 | Step 370256 | Train Loss: 0.3034
Epoch: 1269 | Step 370548 | Train Loss: 0.3029
Epoch: 1270 | Step 370840 | Train Loss: 0.3025
Epoch: 1271 | Step 371132 | Train Loss: 0.3044
Epoch: 1272 | Step 371424 | Train Loss: 0.3038
Epoch: 1273 | Step 371716 | Train Loss: 0.3034
Epoch: 1274 | Step 372000 | Valid Loss: 0.3012
Epoch: 1274 | Step 372000 | Mean Mask Error Rate: 0.3631860453509458
Epoch: 1274 | Step 372008 | Train Loss: 0.3028
Epoch: 1275 | Step 372300 | Train Loss: 0.3023
Epoch: 1276 | Step 372592 | Train Loss: 0.3022
Epoch: 1277 | Step 372884 | Train Loss: 0.3016
Epoch: 1278 | Step 373176 | Train Loss: 0.3011
Epoch: 1279 | Step 373468 | Train Loss: 0.3008
Epoch: 1280 | Step 373760 | Train Loss: 0.3004
Epoch: 1281 | Step 374000 | Valid Loss: 0.3089
Epoch: 1281 | Step 374000 | Mean Mask Error Rate: 0.36345222845164615
Epoch: 1281 | Step 374052 | Train Loss: 0.3053
Epoch: 1282 | Step 374344 | Train Loss: 0.3049
Epoch: 1283 | Step 374636 | Train Loss: 0.3042
Epoch: 1284 | Step 374928 | Train Loss: 0.3038
Epoch: 1285 | Step 375220 | Train Loss: 0.3033
Epoch: 1286 | Step 375512 | Train Loss: 0.3029
Epoch: 1287 | Step 375804 | Train Loss: 0.3024
Epoch: 1288 | Step 376000 | Valid Loss: 0.3109
Epoch: 1288 | Step 376000 | Mean Mask Error Rate: 0.36363107022242924
Epoch: 1288 | Step 376096 | Train Loss: 0.3022
Epoch: 1289 | Step 376388 | Train Loss: 0.3018
Epoch: 1290 | Step 376680 | Train Loss: 0.3013
Epoch: 1291 | Step 376972 | Train Loss: 0.3043
Epoch: 1292 | Step 377264 | Train Loss: 0.3038
Epoch: 1293 | Step 377556 | Train Loss: 0.3031
Epoch: 1294 | Step 377848 | Train Loss: 0.3028
Epoch: 1295 | Step 378000 | Valid Loss: 0.3112
Epoch: 1295 | Step 378000 | Mean Mask Error Rate: 0.3632276364604302
Epoch: 1295 | Step 378140 | Train Loss: 0.3025
Epoch: 1296 | Step 378432 | Train Loss: 0.3020
Epoch: 1297 | Step 378724 | Train Loss: 0.3016
Epoch: 1298 | Step 379016 | Train Loss: 0.3011
Epoch: 1299 | Step 379308 | Train Loss: 0.3004
Epoch: 1300 | Step 379600 | Train Loss: 0.3002
Epoch: 1301 | Step 379892 | Train Loss: 0.3064
Epoch: 1302 | Step 380000 | Valid Loss: 0.3041
Epoch: 1302 | Step 380000 | Mean Mask Error Rate: 0.3633399324560382
Epoch: 1302 | Step 380184 | Train Loss: 0.3057
Epoch: 1303 | Step 380476 | Train Loss: 0.3050
Epoch: 1304 | Step 380768 | Train Loss: 0.3048
Epoch: 1305 | Step 381060 | Train Loss: 0.3041
Epoch: 1306 | Step 381352 | Train Loss: 0.3039
Epoch: 1307 | Step 381644 | Train Loss: 0.3034
Epoch: 1308 | Step 381936 | Train Loss: 0.3027
Epoch: 1309 | Step 382000 | Valid Loss: 0.3304
Epoch: 1309 | Step 382000 | Mean Mask Error Rate: 0.3628907484736063
Epoch: 1309 | Step 382228 | Train Loss: 0.3024
Epoch: 1310 | Step 382520 | Train Loss: 0.3023
Epoch: 1311 | Step 382812 | Train Loss: 0.3037
Epoch: 1312 | Step 383104 | Train Loss: 0.3033
Epoch: 1313 | Step 383396 | Train Loss: 0.3027
Epoch: 1314 | Step 383688 | Train Loss: 0.3022
Epoch: 1315 | Step 383980 | Train Loss: 0.3019
Epoch: 1316 | Step 384000 | Valid Loss: 0.2836
Epoch: 1316 | Step 384000 | Mean Mask Error Rate: 0.3633399324560382
Epoch: 1316 | Step 384272 | Train Loss: 0.3014
Epoch: 1317 | Step 384564 | Train Loss: 0.3011
Epoch: 1318 | Step 384856 | Train Loss: 0.3009
Epoch: 1319 | Step 385148 | Train Loss: 0.3002
Epoch: 1320 | Step 385440 | Train Loss: 0.2998
Epoch: 1321 | Step 385732 | Train Loss: 0.3051
Epoch: 1322 | Step 386000 | Valid Loss: 0.3061
Epoch: 1322 | Step 386000 | Mean Mask Error Rate: 0.3633607280107804
Epoch: 1322 | Step 386024 | Train Loss: 0.3047
Epoch: 1323 | Step 386316 | Train Loss: 0.3040
Epoch: 1324 | Step 386608 | Train Loss: 0.3038
Epoch: 1325 | Step 386900 | Train Loss: 0.3033
Epoch: 1326 | Step 387192 | Train Loss: 0.3028
Epoch: 1327 | Step 387484 | Train Loss: 0.3025
Epoch: 1328 | Step 387776 | Train Loss: 0.3021
Epoch: 1329 | Step 388000 | Valid Loss: 0.3040
Epoch: 1329 | Step 388000 | Mean Mask Error Rate: 0.3633648871217289
Epoch: 1329 | Step 388068 | Train Loss: 0.3013
Epoch: 1330 | Step 388360 | Train Loss: 0.3012
Epoch: 1331 | Step 388652 | Train Loss: 0.3043
Epoch: 1332 | Step 388944 | Train Loss: 0.3037
Epoch: 1333 | Step 389236 | Train Loss: 0.3031
Epoch: 1334 | Step 389528 | Train Loss: 0.3023
Epoch: 1335 | Step 389820 | Train Loss: 0.3023
Epoch: 1336 | Step 390000 | Valid Loss: 0.2999
Epoch: 1336 | Step 390000 | Mean Mask Error Rate: 0.36323179557137864
Epoch: 1336 | Step 390112 | Train Loss: 0.3016
Epoch: 1337 | Step 390404 | Train Loss: 0.3014
Epoch: 1338 | Step 390696 | Train Loss: 0.3010
Epoch: 1339 | Step 390988 | Train Loss: 0.3005
Epoch: 1340 | Step 391280 | Train Loss: 0.3003
Epoch: 1341 | Step 391572 | Train Loss: 0.3050
Epoch: 1342 | Step 391864 | Train Loss: 0.3042
Epoch: 1343 | Step 392000 | Valid Loss: 0.2996
Epoch: 1343 | Step 392000 | Mean Mask Error Rate: 0.36337320534362577
Epoch: 1343 | Step 392156 | Train Loss: 0.3038
Epoch: 1344 | Step 392448 | Train Loss: 0.3034
Epoch: 1345 | Step 392740 | Train Loss: 0.3029
Epoch: 1346 | Step 393032 | Train Loss: 0.3025
Epoch: 1347 | Step 393324 | Train Loss: 0.3019
Epoch: 1348 | Step 393616 | Train Loss: 0.3018
Epoch: 1349 | Step 393908 | Train Loss: 0.3011
Epoch: 1350 | Step 394000 | Valid Loss: 0.3134
Epoch: 1350 | Step 394000 | Mean Mask Error Rate: 0.36314445424146136
Epoch: 1350 | Step 394200 | Train Loss: 0.3011
Epoch: 1351 | Step 394492 | Train Loss: 0.3051
Epoch: 1352 | Step 394784 | Train Loss: 0.3045
Epoch: 1353 | Step 395076 | Train Loss: 0.3041
Epoch: 1354 | Step 395368 | Train Loss: 0.3039
Epoch: 1355 | Step 395660 | Train Loss: 0.3038
Epoch: 1356 | Step 395952 | Train Loss: 0.3038
Epoch: 1357 | Step 396000 | Valid Loss: 0.3183
Epoch: 1357 | Step 396000 | Mean Mask Error Rate: 0.3629780898035236
Epoch: 1357 | Step 396244 | Train Loss: 0.3033
Epoch: 1358 | Step 396536 | Train Loss: 0.3031
Epoch: 1359 | Step 396828 | Train Loss: 0.3029
Epoch: 1360 | Step 397120 | Train Loss: 0.3026
Epoch: 1361 | Step 397412 | Train Loss: 0.3039
Epoch: 1362 | Step 397704 | Train Loss: 0.3035
Epoch: 1363 | Step 397996 | Train Loss: 0.3032
Epoch: 1364 | Step 398000 | Valid Loss: 0.3764
Epoch: 1364 | Step 398000 | Mean Mask Error Rate: 0.3630155218020596
Epoch: 1364 | Step 398288 | Train Loss: 0.3030
Epoch: 1365 | Step 398580 | Train Loss: 0.3027
Epoch: 1366 | Step 398872 | Train Loss: 0.3026
Epoch: 1367 | Step 399164 | Train Loss: 0.3022
Epoch: 1368 | Step 399456 | Train Loss: 0.3022
Epoch: 1369 | Step 399748 | Train Loss: 0.3017
Epoch: 1370 | Step 400000 | Valid Loss: 0.3015
Epoch: 1370 | Step 400000 | Mean Mask Error Rate: 0.3629905671363689
Epoch: 1370 | Step 400040 | Train Loss: 0.3017
Epoch: 1371 | Step 400332 | Train Loss: 0.3045
Epoch: 1372 | Step 400624 | Train Loss: 0.3044
Epoch: 1373 | Step 400916 | Train Loss: 0.3042
Epoch: 1374 | Step 401208 | Train Loss: 0.3038
Epoch: 1375 | Step 401500 | Train Loss: 0.3039
Epoch: 1376 | Step 401792 | Train Loss: 0.3035
Epoch: 1377 | Step 402000 | Valid Loss: 0.3071
Epoch: 1377 | Step 402000 | Mean Mask Error Rate: 0.3628949075845547
Epoch: 1377 | Step 402084 | Train Loss: 0.3031
Epoch: 1378 | Step 402376 | Train Loss: 0.3031
Epoch: 1379 | Step 402668 | Train Loss: 0.3028
Epoch: 1380 | Step 402960 | Train Loss: 0.3025
Epoch: 1381 | Step 403252 | Train Loss: 0.3042
Epoch: 1382 | Step 403544 | Train Loss: 0.3041
Epoch: 1383 | Step 403836 | Train Loss: 0.3036
Epoch: 1384 | Step 404000 | Valid Loss: 0.2984
Epoch: 1384 | Step 404000 | Mean Mask Error Rate: 0.36251642848824633
Epoch: 1384 | Step 404128 | Train Loss: 0.3036
Epoch: 1385 | Step 404420 | Train Loss: 0.3033
Epoch: 1386 | Step 404712 | Train Loss: 0.3032
Epoch: 1387 | Step 405004 | Train Loss: 0.3028
Epoch: 1388 | Step 405296 | Train Loss: 0.3024
Epoch: 1389 | Step 405588 | Train Loss: 0.3021
Epoch: 1390 | Step 405880 | Train Loss: 0.3019
Epoch: 1391 | Step 406000 | Valid Loss: 0.2959
Epoch: 1391 | Step 406000 | Mean Mask Error Rate: 0.3626619973714419
Epoch: 1391 | Step 406172 | Train Loss: 0.3038
Epoch: 1392 | Step 406464 | Train Loss: 0.3038
Epoch: 1393 | Step 406756 | Train Loss: 0.3034
Epoch: 1394 | Step 407048 | Train Loss: 0.3030
Epoch: 1395 | Step 407340 | Train Loss: 0.3029
Epoch: 1396 | Step 407632 | Train Loss: 0.3026
Epoch: 1397 | Step 407924 | Train Loss: 0.3026
Epoch: 1398 | Step 408000 | Valid Loss: 0.3268
Epoch: 1398 | Step 408000 | Mean Mask Error Rate: 0.3624914738225557
Epoch: 1398 | Step 408216 | Train Loss: 0.3023
Epoch: 1399 | Step 408508 | Train Loss: 0.3020
Epoch: 1400 | Step 408800 | Train Loss: 0.3018
Epoch: 1401 | Step 409092 | Train Loss: 0.3054
Epoch: 1402 | Step 409384 | Train Loss: 0.3050
Epoch: 1403 | Step 409676 | Train Loss: 0.3048
Epoch: 1404 | Step 409968 | Train Loss: 0.3045
Epoch: 1405 | Step 410000 | Valid Loss: 0.3057
Epoch: 1405 | Step 410000 | Mean Mask Error Rate: 0.3626328835948028
Epoch: 1405 | Step 410260 | Train Loss: 0.3043
Epoch: 1406 | Step 410552 | Train Loss: 0.3043
Epoch: 1407 | Step 410844 | Train Loss: 0.3039
Epoch: 1408 | Step 411136 | Train Loss: 0.3037
Epoch: 1409 | Step 411428 | Train Loss: 0.3037
Epoch: 1410 | Step 411720 | Train Loss: 0.3034
Epoch: 1411 | Step 412000 | Valid Loss: 0.3065
Epoch: 1411 | Step 412000 | Mean Mask Error Rate: 0.3626952702590294
Epoch: 1411 | Step 412012 | Train Loss: 0.3035
Epoch: 1412 | Step 412304 | Train Loss: 0.3033
Epoch: 1413 | Step 412596 | Train Loss: 0.3033
Epoch: 1414 | Step 412888 | Train Loss: 0.3028
Epoch: 1415 | Step 413180 | Train Loss: 0.3028
Epoch: 1416 | Step 413472 | Train Loss: 0.3023
Epoch: 1417 | Step 413764 | Train Loss: 0.3023
Epoch: 1418 | Step 414000 | Valid Loss: 0.3074
Epoch: 1418 | Step 414000 | Mean Mask Error Rate: 0.36257881515247303
Epoch: 1418 | Step 414056 | Train Loss: 0.3019
Epoch: 1419 | Step 414348 | Train Loss: 0.3018
Epoch: 1420 | Step 414640 | Train Loss: 0.3013
Epoch: 1421 | Step 414932 | Train Loss: 0.3030
Epoch: 1422 | Step 415224 | Train Loss: 0.3024
Epoch: 1423 | Step 415516 | Train Loss: 0.3023
Epoch: 1424 | Step 415808 | Train Loss: 0.3024
Epoch: 1425 | Step 416000 | Valid Loss: 0.3086
Epoch: 1425 | Step 416000 | Mean Mask Error Rate: 0.36260376981816367
Epoch: 1425 | Step 416100 | Train Loss: 0.3018
Epoch: 1426 | Step 416392 | Train Loss: 0.3016
Epoch: 1427 | Step 416684 | Train Loss: 0.3014
Epoch: 1428 | Step 416976 | Train Loss: 0.3015
Epoch: 1429 | Step 417268 | Train Loss: 0.3012
Epoch: 1430 | Step 417560 | Train Loss: 0.3010
Epoch: 1431 | Step 417852 | Train Loss: 0.3053
Epoch: 1432 | Step 418000 | Valid Loss: 0.3104
Epoch: 1432 | Step 418000 | Mean Mask Error Rate: 0.3625205875991948
Epoch: 1432 | Step 418144 | Train Loss: 0.3051
Epoch: 1433 | Step 418436 | Train Loss: 0.3051
Epoch: 1434 | Step 418728 | Train Loss: 0.3049
Epoch: 1435 | Step 419020 | Train Loss: 0.3049
Epoch: 1436 | Step 419312 | Train Loss: 0.3045
Epoch: 1437 | Step 419604 | Train Loss: 0.3046
Epoch: 1438 | Step 419896 | Train Loss: 0.3046
Epoch: 1439 | Step 420000 | Valid Loss: 0.2951
Epoch: 1439 | Step 420000 | Mean Mask Error Rate: 0.36242076893643216
Epoch: 1439 | Step 420188 | Train Loss: 0.3042
Epoch: 1440 | Step 420480 | Train Loss: 0.3044
Epoch: 1441 | Step 420772 | Train Loss: 0.3039
Epoch: 1442 | Step 421064 | Train Loss: 0.3038
Epoch: 1443 | Step 421356 | Train Loss: 0.3036
Epoch: 1444 | Step 421648 | Train Loss: 0.3034
Epoch: 1445 | Step 421940 | Train Loss: 0.3033
Epoch: 1446 | Step 422000 | Valid Loss: 0.3028
Epoch: 1446 | Step 422000 | Mean Mask Error Rate: 0.3626495200385966
Epoch: 1446 | Step 422232 | Train Loss: 0.3033
Epoch: 1447 | Step 422524 | Train Loss: 0.3031
Epoch: 1448 | Step 422816 | Train Loss: 0.3030
Epoch: 1449 | Step 423108 | Train Loss: 0.3026
Epoch: 1450 | Step 423400 | Train Loss: 0.3027
Epoch: 1451 | Step 423692 | Train Loss: 0.3043
Epoch: 1452 | Step 423984 | Train Loss: 0.3042
Epoch: 1453 | Step 424000 | Valid Loss: 0.3345
Epoch: 1453 | Step 424000 | Mean Mask Error Rate: 0.3626661564823903
Epoch: 1453 | Step 424276 | Train Loss: 0.3041
Epoch: 1454 | Step 424568 | Train Loss: 0.3038
Epoch: 1455 | Step 424860 | Train Loss: 0.3036
Epoch: 1456 | Step 425152 | Train Loss: 0.3036
Epoch: 1457 | Step 425444 | Train Loss: 0.3033
Epoch: 1458 | Step 425736 | Train Loss: 0.3035
Epoch: 1459 | Step 426000 | Valid Loss: 0.3073
Epoch: 1459 | Step 426000 | Mean Mask Error Rate: 0.3625289058210917
Epoch: 1459 | Step 426028 | Train Loss: 0.3033
Epoch: 1460 | Step 426320 | Train Loss: 0.3031
Epoch: 1461 | Step 426612 | Train Loss: 0.3056
Epoch: 1462 | Step 426904 | Train Loss: 0.3054
Epoch: 1463 | Step 427196 | Train Loss: 0.3052
Epoch: 1464 | Step 427488 | Train Loss: 0.3050
Epoch: 1465 | Step 427780 | Train Loss: 0.3050
Epoch: 1466 | Step 428000 | Valid Loss: 0.3008
Epoch: 1466 | Step 428000 | Mean Mask Error Rate: 0.36237917782694773
Epoch: 1466 | Step 428072 | Train Loss: 0.3048
Epoch: 1467 | Step 428364 | Train Loss: 0.3046
Epoch: 1468 | Step 428656 | Train Loss: 0.3047
Epoch: 1469 | Step 428948 | Train Loss: 0.3046
Epoch: 1470 | Step 429240 | Train Loss: 0.3043
Epoch: 1471 | Step 429532 | Train Loss: 0.3035
Epoch: 1472 | Step 429824 | Train Loss: 0.3035
Epoch: 1473 | Step 430000 | Valid Loss: 0.2984
Epoch: 1473 | Step 430000 | Mean Mask Error Rate: 0.3623126320517726
Epoch: 1473 | Step 430116 | Train Loss: 0.3031
Epoch: 1474 | Step 430408 | Train Loss: 0.3030
Epoch: 1475 | Step 430700 | Train Loss: 0.3029
Epoch: 1476 | Step 430992 | Train Loss: 0.3030
Epoch: 1477 | Step 431284 | Train Loss: 0.3027
Epoch: 1478 | Step 431576 | Train Loss: 0.3023
Epoch: 1479 | Step 431868 | Train Loss: 0.3024
Epoch: 1480 | Step 432000 | Valid Loss: 0.3190
Epoch: 1480 | Step 432000 | Mean Mask Error Rate: 0.36226688183133976
Epoch: 1480 | Step 432160 | Train Loss: 0.3023
Epoch: 1481 | Step 432452 | Train Loss: 0.3044
Epoch: 1482 | Step 432744 | Train Loss: 0.3045
Epoch: 1483 | Step 433036 | Train Loss: 0.3046
Epoch: 1484 | Step 433328 | Train Loss: 0.3041
Epoch: 1485 | Step 433620 | Train Loss: 0.3042
Epoch: 1486 | Step 433912 | Train Loss: 0.3038
Epoch: 1487 | Step 434000 | Valid Loss: 0.2912
Epoch: 1487 | Step 434000 | Mean Mask Error Rate: 0.36240829160358684
Epoch: 1487 | Step 434204 | Train Loss: 0.3038
Epoch: 1488 | Step 434496 | Train Loss: 0.3036
Epoch: 1489 | Step 434788 | Train Loss: 0.3036
Epoch: 1490 | Step 435080 | Train Loss: 0.3035
Epoch: 1491 | Step 435372 | Train Loss: 0.3036
Epoch: 1492 | Step 435664 | Train Loss: 0.3033
Epoch: 1493 | Step 435956 | Train Loss: 0.3035
Epoch: 1494 | Step 436000 | Valid Loss: 0.3043
Epoch: 1494 | Step 436000 | Mean Mask Error Rate: 0.36236254138315394
Epoch: 1494 | Step 436248 | Train Loss: 0.3034
Epoch: 1495 | Step 436540 | Train Loss: 0.3030
Epoch: 1496 | Step 436832 | Train Loss: 0.3031
Epoch: 1497 | Step 437124 | Train Loss: 0.3030
Epoch: 1498 | Step 437416 | Train Loss: 0.3027
Epoch: 1499 | Step 437708 | Train Loss: 0.3026
Epoch: 1500 | Step 438000 | Valid Loss: 0.3024
Epoch: 1500 | Step 438000 | Mean Mask Error Rate: 0.36220033605616464
Epoch: 1500 | Step 438 | Train Loss: 0.3024
Epoch: 1501 | Step 438292 | Train Loss: 0.3033
Epoch: 1502 | Step 438584 | Train Loss: 0.3030
Epoch: 1503 | Step 438876 | Train Loss: 0.3025
Epoch: 1504 | Step 439168 | Train Loss: 0.3027
Epoch: 1505 | Step 439460 | Train Loss: 0.3025
Epoch: 1506 | Step 439752 | Train Loss: 0.3025
Epoch: 1507 | Step 440000 | Valid Loss: 0.3033
Epoch: 1507 | Step 440000 | Mean Mask Error Rate: 0.3620838809496082
Epoch: 1507 | Step 440044 | Train Loss: 0.3025
Epoch: 1508 | Step 440336 | Train Loss: 0.3022
Epoch: 1509 | Step 440628 | Train Loss: 0.3022
Epoch: 1510 | Step 440920 | Train Loss: 0.3021
Epoch: 1511 | Step 441212 | Train Loss: 0.3036
Epoch: 1512 | Step 441504 | Train Loss: 0.3033
Epoch: 1513 | Step 441796 | Train Loss: 0.3036
Epoch: 1514 | Step 442000 | Valid Loss: 0.2985
Epoch: 1514 | Step 442000 | Mean Mask Error Rate: 0.36202981250727845
Epoch: 1514 | Step 442088 | Train Loss: 0.3036
Epoch: 1515 | Step 442380 | Train Loss: 0.3032
Epoch: 1516 | Step 442672 | Train Loss: 0.3031
Epoch: 1517 | Step 442964 | Train Loss: 0.3031
Epoch: 1518 | Step 443256 | Train Loss: 0.3028
Epoch: 1519 | Step 443548 | Train Loss: 0.3028
Epoch: 1520 | Step 443840 | Train Loss: 0.3026
Epoch: 1521 | Step 444000 | Valid Loss: 0.3008
Epoch: 1521 | Step 444000 | Mean Mask Error Rate: 0.36223360894375217
Epoch: 1521 | Step 444132 | Train Loss: 0.3045
Epoch: 1522 | Step 444424 | Train Loss: 0.3042
Epoch: 1523 | Step 444716 | Train Loss: 0.3041
Epoch: 1524 | Step 445008 | Train Loss: 0.3039
Epoch: 1525 | Step 445300 | Train Loss: 0.3039
Epoch: 1526 | Step 445592 | Train Loss: 0.3034
Epoch: 1527 | Step 445884 | Train Loss: 0.3037
Epoch: 1528 | Step 446000 | Valid Loss: 0.3112
Epoch: 1528 | Step 446000 | Mean Mask Error Rate: 0.36236670049410236
Epoch: 1528 | Step 446176 | Train Loss: 0.3036
Epoch: 1529 | Step 446468 | Train Loss: 0.3034
Epoch: 1530 | Step 446760 | Train Loss: 0.3031
Epoch: 1531 | Step 447052 | Train Loss: 0.3040
Epoch: 1532 | Step 447344 | Train Loss: 0.3038
Epoch: 1533 | Step 447636 | Train Loss: 0.3036
Epoch: 1534 | Step 447928 | Train Loss: 0.3034
Epoch: 1535 | Step 448000 | Valid Loss: 0.2917
Epoch: 1535 | Step 448000 | Mean Mask Error Rate: 0.3622710409422882
Epoch: 1535 | Step 448220 | Train Loss: 0.3034
Epoch: 1536 | Step 448512 | Train Loss: 0.3032
Epoch: 1537 | Step 448804 | Train Loss: 0.3031
Epoch: 1538 | Step 449096 | Train Loss: 0.3029
Epoch: 1539 | Step 449388 | Train Loss: 0.3026
Epoch: 1540 | Step 449680 | Train Loss: 0.3026
Epoch: 1541 | Step 449972 | Train Loss: 0.3044
Epoch: 1542 | Step 450000 | Valid Loss: 0.2863
Epoch: 1542 | Step 450000 | Mean Mask Error Rate: 0.3622793591641851
Epoch: 1542 | Step 450264 | Train Loss: 0.3041
Epoch: 1543 | Step 450556 | Train Loss: 0.3040
Epoch: 1544 | Step 450848 | Train Loss: 0.3039
Epoch: 1545 | Step 451140 | Train Loss: 0.3038
Epoch: 1546 | Step 451432 | Train Loss: 0.3038
Epoch: 1547 | Step 451724 | Train Loss: 0.3034
Epoch: 1548 | Step 452000 | Valid Loss: 0.3022
Epoch: 1548 | Step 452000 | Mean Mask Error Rate: 0.36219617694521616
Epoch: 1548 | Step 452016 | Train Loss: 0.3034
Epoch: 1549 | Step 452308 | Train Loss: 0.3034
Epoch: 1550 | Step 452600 | Train Loss: 0.3031
Epoch: 1551 | Step 452892 | Train Loss: 0.3039
Epoch: 1552 | Step 453184 | Train Loss: 0.3037
Epoch: 1553 | Step 453476 | Train Loss: 0.3036
Epoch: 1554 | Step 453768 | Train Loss: 0.3033
Epoch: 1555 | Step 454000 | Valid Loss: 0.3036
Epoch: 1555 | Step 454000 | Mean Mask Error Rate: 0.36204228984012377
Epoch: 1555 | Step 454060 | Train Loss: 0.3032
Epoch: 1556 | Step 454352 | Train Loss: 0.3030
Epoch: 1557 | Step 454644 | Train Loss: 0.3031
Epoch: 1558 | Step 454936 | Train Loss: 0.3029
Epoch: 1559 | Step 455228 | Train Loss: 0.3029
Epoch: 1560 | Step 455520 | Train Loss: 0.3029
Epoch: 1561 | Step 455812 | Train Loss: 0.3031
Epoch: 1562 | Step 456000 | Valid Loss: 0.3049
Epoch: 1562 | Step 456000 | Mean Mask Error Rate: 0.3621254720590926
Epoch: 1562 | Step 456104 | Train Loss: 0.3028
Epoch: 1563 | Step 456396 | Train Loss: 0.3031
Epoch: 1564 | Step 456688 | Train Loss: 0.3029
Epoch: 1565 | Step 456980 | Train Loss: 0.3030
Epoch: 1566 | Step 457272 | Train Loss: 0.3029
Epoch: 1567 | Step 457564 | Train Loss: 0.3028
Epoch: 1568 | Step 457856 | Train Loss: 0.3025
Epoch: 1569 | Step 458000 | Valid Loss: 0.2955
Epoch: 1569 | Step 458000 | Mean Mask Error Rate: 0.36206724450581446
Epoch: 1569 | Step 458148 | Train Loss: 0.3026
Epoch: 1570 | Step 458440 | Train Loss: 0.3025
Epoch: 1571 | Step 458732 | Train Loss: 0.3045
Epoch: 1572 | Step 459024 | Train Loss: 0.3044
Epoch: 1573 | Step 459316 | Train Loss: 0.3045
Epoch: 1574 | Step 459608 | Train Loss: 0.3044
Epoch: 1575 | Step 459900 | Train Loss: 0.3041
Epoch: 1576 | Step 460000 | Valid Loss: 0.2917
Epoch: 1576 | Step 460000 | Mean Mask Error Rate: 0.36206724450581446
Epoch: 1576 | Step 460192 | Train Loss: 0.3044
Epoch: 1577 | Step 460484 | Train Loss: 0.3041
Epoch: 1578 | Step 460776 | Train Loss: 0.3041
Epoch: 1579 | Step 461068 | Train Loss: 0.3039
Epoch: 1580 | Step 461360 | Train Loss: 0.3040
Epoch: 1581 | Step 461652 | Train Loss: 0.3039
Epoch: 1582 | Step 461944 | Train Loss: 0.3039
Epoch: 1583 | Step 462000 | Valid Loss: 0.3190
Epoch: 1583 | Step 462000 | Mean Mask Error Rate: 0.362287677386082
Epoch: 1583 | Step 462236 | Train Loss: 0.3039
Epoch: 1584 | Step 462528 | Train Loss: 0.3038
Epoch: 1585 | Step 462820 | Train Loss: 0.3039
Epoch: 1586 | Step 463112 | Train Loss: 0.3038
Epoch: 1587 | Step 463404 | Train Loss: 0.3034
Epoch: 1588 | Step 463696 | Train Loss: 0.3035
Epoch: 1589 | Step 463988 | Train Loss: 0.3035
Epoch: 1590 | Step 464000 | Valid Loss: 0.2503
Epoch: 1590 | Step 464000 | Mean Mask Error Rate: 0.3623375867174633
Epoch: 1590 | Step 464280 | Train Loss: 0.3034
Epoch: 1591 | Step 464572 | Train Loss: 0.3034
Epoch: 1592 | Step 464864 | Train Loss: 0.3032
Epoch: 1593 | Step 465156 | Train Loss: 0.3031
Epoch: 1594 | Step 465448 | Train Loss: 0.3032
Epoch: 1595 | Step 465740 | Train Loss: 0.3032
Epoch: 1596 | Step 466000 | Valid Loss: 0.2982
Epoch: 1596 | Step 466000 | Mean Mask Error Rate: 0.3623583822722055
Epoch: 1596 | Step 466032 | Train Loss: 0.3031
Epoch: 1597 | Step 466324 | Train Loss: 0.3029
Epoch: 1598 | Step 466616 | Train Loss: 0.3030
Epoch: 1599 | Step 466908 | Train Loss: 0.3028
Epoch: 1600 | Step 467200 | Train Loss: 0.3027
Epoch: 1601 | Step 467492 | Train Loss: 0.3037
Epoch: 1602 | Step 467784 | Train Loss: 0.3039
Epoch: 1603 | Step 468000 | Valid Loss: 0.2976
Epoch: 1603 | Step 468000 | Mean Mask Error Rate: 0.3622544044984944
Epoch: 1603 | Step 468076 | Train Loss: 0.3036
Epoch: 1604 | Step 468368 | Train Loss: 0.3037
Epoch: 1605 | Step 468660 | Train Loss: 0.3035
Epoch: 1606 | Step 468952 | Train Loss: 0.3037
Epoch: 1607 | Step 469244 | Train Loss: 0.3035
Epoch: 1608 | Step 469536 | Train Loss: 0.3033
Epoch: 1609 | Step 469828 | Train Loss: 0.3035
Epoch: 1610 | Step 470000 | Valid Loss: 0.3052
Epoch: 1610 | Step 470000 | Mean Mask Error Rate: 0.36223360894375217
Epoch: 1610 | Step 470120 | Train Loss: 0.3036
Epoch: 1611 | Step 470412 | Train Loss: 0.3034
Epoch: 1612 | Step 470704 | Train Loss: 0.3032
Epoch: 1613 | Step 470996 | Train Loss: 0.3032
Epoch: 1614 | Step 471288 | Train Loss: 0.3033
Epoch: 1615 | Step 471580 | Train Loss: 0.3030
Epoch: 1616 | Step 471872 | Train Loss: 0.3030
Epoch: 1617 | Step 472000 | Valid Loss: 0.2992
Epoch: 1617 | Step 472000 | Mean Mask Error Rate: 0.36219617694521616
Epoch: 1617 | Step 472164 | Train Loss: 0.3034
Epoch: 1618 | Step 472456 | Train Loss: 0.3031
Epoch: 1619 | Step 472748 | Train Loss: 0.3030
Epoch: 1620 | Step 473040 | Train Loss: 0.3029
Epoch: 1621 | Step 473332 | Train Loss: 0.3036
Epoch: 1622 | Step 473624 | Train Loss: 0.3036
Epoch: 1623 | Step 473916 | Train Loss: 0.3036
Epoch: 1624 | Step 474000 | Valid Loss: 0.2901
Epoch: 1624 | Step 474000 | Mean Mask Error Rate: 0.3622460862765975
Epoch: 1624 | Step 474208 | Train Loss: 0.3036
Epoch: 1625 | Step 474500 | Train Loss: 0.3032
Epoch: 1626 | Step 474792 | Train Loss: 0.3034
Epoch: 1627 | Step 475084 | Train Loss: 0.3036
Epoch: 1628 | Step 475376 | Train Loss: 0.3034
Epoch: 1629 | Step 475668 | Train Loss: 0.3033
Epoch: 1630 | Step 475960 | Train Loss: 0.3033
Epoch: 1631 | Step 476000 | Valid Loss: 0.3037
Epoch: 1631 | Step 476000 | Mean Mask Error Rate: 0.3621421085028864
Epoch: 1631 | Step 476252 | Train Loss: 0.3047
Epoch: 1632 | Step 476544 | Train Loss: 0.3047
Epoch: 1633 | Step 476836 | Train Loss: 0.3045
Epoch: 1634 | Step 477128 | Train Loss: 0.3046
Epoch: 1635 | Step 477420 | Train Loss: 0.3047
Epoch: 1636 | Step 477712 | Train Loss: 0.3046
Epoch: 1637 | Step 478000 | Valid Loss: 0.3043
Epoch: 1637 | Step 478000 | Mean Mask Error Rate: 0.36225024538754597
Epoch: 1637 | Step 478004 | Train Loss: 0.3045
Epoch: 1638 | Step 478296 | Train Loss: 0.3046
Epoch: 1639 | Step 478588 | Train Loss: 0.3046
Epoch: 1640 | Step 478880 | Train Loss: 0.3045
Epoch: 1641 | Step 479172 | Train Loss: 0.3029
Epoch: 1642 | Step 479464 | Train Loss: 0.3027
Epoch: 1643 | Step 479756 | Train Loss: 0.3030
Epoch: 1644 | Step 480000 | Valid Loss: 0.2947
Epoch: 1644 | Step 480000 | Mean Mask Error Rate: 0.3622710409422882
Epoch: 1644 | Step 480048 | Train Loss: 0.3028
Epoch: 1645 | Step 480340 | Train Loss: 0.3031
Epoch: 1646 | Step 480632 | Train Loss: 0.3030
Epoch: 1647 | Step 480924 | Train Loss: 0.3030
Epoch: 1648 | Step 481216 | Train Loss: 0.3028
Epoch: 1649 | Step 481508 | Train Loss: 0.3026
Epoch: 1650 | Step 481800 | Train Loss: 0.3029
Epoch: 1651 | Step 482000 | Valid Loss: 0.3071
Epoch: 1651 | Step 482000 | Mean Mask Error Rate: 0.3622752000532366
Epoch: 1651 | Step 482092 | Train Loss: 0.3048
Epoch: 1652 | Step 482384 | Train Loss: 0.3048
Epoch: 1653 | Step 482676 | Train Loss: 0.3045
Epoch: 1654 | Step 482968 | Train Loss: 0.3046
Epoch: 1655 | Step 483260 | Train Loss: 0.3044
Epoch: 1656 | Step 483552 | Train Loss: 0.3044
Epoch: 1657 | Step 483844 | Train Loss: 0.3045
Epoch: 1658 | Step 484000 | Valid Loss: 0.3146
Epoch: 1658 | Step 484000 | Mean Mask Error Rate: 0.36221697249995843
Epoch: 1658 | Step 484136 | Train Loss: 0.3044
Epoch: 1659 | Step 484428 | Train Loss: 0.3042
Epoch: 1660 | Step 484720 | Train Loss: 0.3045
Epoch: 1661 | Step 485012 | Train Loss: 0.3033
Epoch: 1662 | Step 485304 | Train Loss: 0.3031
Epoch: 1663 | Step 485596 | Train Loss: 0.3031
Epoch: 1664 | Step 485888 | Train Loss: 0.3031
Epoch: 1665 | Step 486000 | Valid Loss: 0.3045
Epoch: 1665 | Step 486000 | Mean Mask Error Rate: 0.36221281338900996
Epoch: 1665 | Step 486180 | Train Loss: 0.3029
Epoch: 1666 | Step 486472 | Train Loss: 0.3033
Epoch: 1667 | Step 486764 | Train Loss: 0.3030
Epoch: 1668 | Step 487056 | Train Loss: 0.3032
Epoch: 1669 | Step 487348 | Train Loss: 0.3030
Epoch: 1670 | Step 487640 | Train Loss: 0.3033
Epoch: 1671 | Step 487932 | Train Loss: 0.3038
Epoch: 1672 | Step 488000 | Valid Loss: 0.2935
Epoch: 1672 | Step 488000 | Mean Mask Error Rate: 0.36220033605616464
Epoch: 1672 | Step 488224 | Train Loss: 0.3037
Epoch: 1673 | Step 488516 | Train Loss: 0.3037
Epoch: 1674 | Step 488808 | Train Loss: 0.3034
Epoch: 1675 | Step 489100 | Train Loss: 0.3034
Epoch: 1676 | Step 489392 | Train Loss: 0.3038
Epoch: 1677 | Step 489684 | Train Loss: 0.3036
Epoch: 1678 | Step 489976 | Train Loss: 0.3035
Epoch: 1679 | Step 490000 | Valid Loss: 0.3006
Epoch: 1679 | Step 490000 | Mean Mask Error Rate: 0.36221281338900996
Epoch: 1679 | Step 490268 | Train Loss: 0.3034
Epoch: 1680 | Step 490560 | Train Loss: 0.3036
Epoch: 1681 | Step 490852 | Train Loss: 0.3035
Epoch: 1682 | Step 491144 | Train Loss: 0.3038
Epoch: 1683 | Step 491436 | Train Loss: 0.3036
Epoch: 1684 | Step 491728 | Train Loss: 0.3036
Epoch: 1685 | Step 492000 | Valid Loss: 0.3053
Epoch: 1685 | Step 492000 | Mean Mask Error Rate: 0.36217538139047395
Epoch: 1685 | Step 492020 | Train Loss: 0.3036
Epoch: 1686 | Step 492312 | Train Loss: 0.3036
Epoch: 1687 | Step 492604 | Train Loss: 0.3035
Epoch: 1688 | Step 492896 | Train Loss: 0.3034
Epoch: 1689 | Step 493188 | Train Loss: 0.3038
Epoch: 1690 | Step 493480 | Train Loss: 0.3034
Epoch: 1691 | Step 493772 | Train Loss: 0.3026
Epoch: 1692 | Step 494000 | Valid Loss: 0.3047
Epoch: 1692 | Step 494000 | Mean Mask Error Rate: 0.3621795405014224
Epoch: 1692 | Step 494064 | Train Loss: 0.3025
Epoch: 1693 | Step 494356 | Train Loss: 0.3027
Epoch: 1694 | Step 494648 | Train Loss: 0.3029
Epoch: 1695 | Step 494940 | Train Loss: 0.3026
Epoch: 1696 | Step 495232 | Train Loss: 0.3028
Epoch: 1697 | Step 495524 | Train Loss: 0.3027
Epoch: 1698 | Step 495816 | Train Loss: 0.3027
Epoch: 1699 | Step 496000 | Valid Loss: 0.3067
Epoch: 1699 | Step 496000 | Mean Mask Error Rate: 0.3621462676138349
Epoch: 1699 | Step 496108 | Train Loss: 0.3025
Epoch: 1700 | Step 496400 | Train Loss: 0.3026
Epoch: 1701 | Step 496692 | Train Loss: 0.3037
Epoch: 1702 | Step 496984 | Train Loss: 0.3038
Epoch: 1703 | Step 497276 | Train Loss: 0.3040
Epoch: 1704 | Step 497568 | Train Loss: 0.3040
Epoch: 1705 | Step 497860 | Train Loss: 0.3038
Epoch: 1706 | Step 498000 | Valid Loss: 0.2983
Epoch: 1706 | Step 498000 | Mean Mask Error Rate: 0.3622544044984944
Epoch: 1706 | Step 498152 | Train Loss: 0.3038
Epoch: 1707 | Step 498444 | Train Loss: 0.3041
Epoch: 1708 | Step 498736 | Train Loss: 0.3037
Epoch: 1709 | Step 499028 | Train Loss: 0.3040
Epoch: 1710 | Step 499320 | Train Loss: 0.3040
Epoch: 1711 | Step 499612 | Train Loss: 0.3030
Epoch: 1712 | Step 499904 | Train Loss: 0.3028
Epoch: 1713 | Step 500000 | Valid Loss: 0.3044
Epoch: 1713 | Step 500000 | Mean Mask Error Rate: 0.3622460862765975
Epoch: 1713 | Step 500196 | Train Loss: 0.3028
Epoch: 1714 | Step 500488 | Train Loss: 0.3027
Epoch: 1715 | Step 500780 | Train Loss: 0.3024
Epoch: 1716 | Step 501072 | Train Loss: 0.3027
Epoch: 1717 | Step 501364 | Train Loss: 0.3026
Epoch: 1718 | Step 501656 | Train Loss: 0.3026
Epoch: 1719 | Step 501948 | Train Loss: 0.3026
Epoch: 1720 | Step 502000 | Valid Loss: 0.2909
Epoch: 1720 | Step 502000 | Mean Mask Error Rate: 0.36221281338900996
Epoch: 1720 | Step 502240 | Train Loss: 0.3025
Epoch: 1721 | Step 502532 | Train Loss: 0.3041
Epoch: 1722 | Step 502824 | Train Loss: 0.3041
